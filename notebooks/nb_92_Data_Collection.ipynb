{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:57:59.047241Z",
     "start_time": "2024-05-06T18:57:57.808998Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext training_rl\n",
    "%set_random_seed 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:57:59.059228Z",
     "start_time": "2024-05-06T18:57:59.048394Z"
    }
   },
   "outputs": [],
   "source": [
    "%presentation_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T18:57:59.071940Z",
     "start_time": "2024-05-06T18:57:59.059990Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_latex_macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T19:32:10.050468Z",
     "start_time": "2024-05-06T19:32:10.021939Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from training_rl.offline_rl.load_env_variables import load_env_variables\n",
    "load_env_variables()\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import gymnasium as gym\n",
    "import minari\n",
    "import numpy as np\n",
    "from minari import DataCollectorV0, StepDataCallback\n",
    "\n",
    "from training_rl.offline_rl.custom_envs.custom_2d_grid_env.obstacles_2D_grid_register import \\\n",
    "    ObstacleTypes\n",
    "from training_rl.offline_rl.custom_envs.custom_2d_grid_env.simple_grid import \\\n",
    "    Custom2DGridEnv\n",
    "from training_rl.offline_rl.custom_envs.custom_envs_registration import (\n",
    "    CustomEnv, RenderMode, register_grid_envs)\n",
    "from training_rl.offline_rl.custom_envs.utils import (\n",
    "    Grid2DInitialConfig, InitialConfigCustom2DGridEnvWrapper)\n",
    "from training_rl.offline_rl.generate_custom_minari_datasets.utils import \\\n",
    "    generate_compatible_minari_dataset_name\n",
    "from training_rl.offline_rl.offline_policies.offpolicy_rendering import \\\n",
    "    offpolicy_rendering\n",
    "from training_rl.offline_rl.utils import (delete_minari_data_if_exists,\n",
    "                                          load_buffer_minari,\n",
    "                                          one_hot_to_integer,\n",
    "                                          state_action_histogram)\n",
    "from training_rl.offline_rl.visualizations.utils import (\n",
    "    get_state_action_data_and_policy_grid_distributions, snapshot_env)\n",
    "from training_rl.offline_rl.utils import widget_list\n",
    "from training_rl.offline_rl.behavior_policies.behavior_policy_registry import BehaviorPolicyType\n",
    "from training_rl.offline_rl.custom_envs.custom_envs_registration import EnvFactory\n",
    "from training_rl.offline_rl.generate_custom_minari_datasets.generate_minari_dataset_grid_envs import \\\n",
    "    create_minari_datasets\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# To get access to the registered environments.\n",
    "register_grid_envs()\n",
    "\n",
    "render_mode = RenderMode.RGB_ARRAY_LIST if os.environ.get(\"DISPLAY\") else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"_static/images/aai-institute-cover.svg\" alt=\"Snow\" style=\"width:100%;\">\n",
    "<div class=\"md-slide title\"> Minari Overview </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise: Minari data collection\n",
    "\n",
    "In this exercise you don't have any homework. The idea is to play around with it to get familiar with the code  (notebooks and source code) and with the way we collect data.\n",
    "\n",
    "Remember that the pipeline for offline learning will be the following:\n",
    "\n",
    "<img src=\"_static/images/93_offline_RL_pipeline.png\" alt=\"Snow\" style=\"width:50%;\">\n",
    "\n",
    "In this notebook we will be exploring the steps 1-2-3 . It would be a good idea now to give a look to the code structure:\n",
    "\n",
    "<img src=\"_static/images/93_code_structure.png\" alt=\"Snow\" style=\"width:20%;\">\n",
    "\n",
    "You can also give a look to [Minari documentation](https://minari.farama.org/main/content/basic_usage/) if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## STEP 1: Create the environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T20:00:44.764763Z",
     "start_time": "2024-05-06T20:00:44.747071Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# List of different environments \n",
    "ENV_LIST = [\n",
    "    EnvFactory.Grid_2D_8x8_discrete,\n",
    "    \"InvertedPendulum-v4\", \n",
    "    \"Humanoid-v4\", \n",
    "    \"AdroitHandHammer-v1\",\n",
    "    \"HalfCheetah-v4\",\n",
    "]\n",
    "\n",
    "# obstacles to be used with the 2d grid-world\n",
    "grid_world_obstacles = [\n",
    "    ObstacleTypes.door_object_8x8,\n",
    "    ObstacleTypes.obst_free_8x8, \n",
    "]\n",
    "\n",
    "# behavior policies to be used with 2d grid-world\n",
    "behavior_policy_grid_world = [\n",
    "    BehaviorPolicyType.behavior_8x8_suboptimal_initial_0_0_final_0_7,\n",
    "    BehaviorPolicyType.random,\n",
    "    BehaviorPolicyType.behavior_8x8_grid_deterministic_0_0_to_4_7,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T20:00:46.734844Z",
     "start_time": "2024-05-06T20:00:46.715804Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "selected_environment = widget_list(ENV_LIST, description=\"Mixed envs.\")\n",
    "selected_obstacle = widget_list(grid_world_obstacles, description=\"grid obst.\" )\n",
    "selected_grid_world_policy = widget_list(behavior_policy_grid_world, description=\"grid policy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Select and render behavior policies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T20:03:20.020602Z",
     "start_time": "2024-05-06T20:03:18.658070Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "behavior_policy = BehaviorPolicyType.random\n",
    "if isinstance(selected_environment.value, EnvFactory):\n",
    "    env = EnvFactory[selected_environment.value].get_env(render_mode=RenderMode.RGB_ARRAY_LIST)\n",
    "    if isinstance(env.unwrapped, Custom2DGridEnv):\n",
    "        env.set_new_obstacle_map(selected_obstacle.value.value)\n",
    "        behavior_policy = selected_grid_world_policy.value\n",
    "else:\n",
    "    env = gym.make(selected_environment.value, render_mode=\"rgb_array_list\")\n",
    "    \n",
    "offpolicy_rendering(\n",
    "    env_or_env_name=env,\n",
    "    render_mode=RenderMode.RGB_ARRAY_LIST,\n",
    "    behavior_policy_name=BehaviorPolicyType.random,\n",
    "    num_frames=100,\n",
    "    fps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## STEP 2: Create Minari datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T20:03:20.514392Z",
     "start_time": "2024-05-06T20:03:20.470428Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "DATA_SET_IDENTIFIER_I = \"_collected_data_nb_92\"\n",
    "NUM_STEPS_I = 500\n",
    "\n",
    "data_set_config = create_minari_datasets(\n",
    "    env_name=env.unwrapped.spec.id,\n",
    "    dataset_identifier=DATA_SET_IDENTIFIER_I,\n",
    "    num_colected_points=NUM_STEPS_I,\n",
    "    behavior_policy_name=behavior_policy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: Feed dataset to Tianshou ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T20:03:24.027377Z",
     "start_time": "2024-05-06T20:03:24.003192Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "buffer_data = load_buffer_minari(data_set_config.data_set_name)\n",
    "print(f\"The number of dataset points is {len(buffer_data)}\")\n",
    "\n",
    "for elem in buffer_data:\n",
    "    print(elem)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Let's collect and visualize the 2d grid world data with one of its behavior policies**\n",
    "\n",
    "**Useful information:**\n",
    "\n",
    "In our grid world environment, the agent's position is represented as $(x_1, x_2)$, with $x_1/x_2$ the vertical/horizontal coordinates. Observations are represented as a one-hot encoded vector of dimensions $x_1 \\times x_2$, for example, a 64-dimensional vector in an 8x8 grid,\n",
    " \n",
    "\n",
    "The action is represented by an integer in the range of [0, 1, 2, 3], each indicating a direction:\n",
    "\n",
    "    0: (-1, 0) - UP\n",
    "    1: (1, 0) - DOWN\n",
    "    2: (0, -1) - LEFT\n",
    "    3: (0, 1) - RIGHT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T20:11:42.170993Z",
     "start_time": "2024-05-06T20:11:41.529595Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Compute state-action data distribution\n",
    "if isinstance(env.unwrapped, Custom2DGridEnv):\n",
    "    state_action_count_data, _ = get_state_action_data_and_policy_grid_distributions(buffer_data, env)\n",
    "    new_keys = [(env.to_xy(state_action[0]), state_action[1]) for state_action in list(state_action_count_data.keys())]\n",
    "    state_action_histogram(state_action_count_data, title=\"State-Action data distribution\")\n",
    "    snapshot_env(env)\n",
    "else:\n",
    "    raise ValueError(f\"To analyze the data the environment should be of type {Custom2DGridEnv}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "[ \\[Fu.Justin et. al.\\] D4RL: Datasets for Deep Data-Driven Reinforcement Learning](https://arxiv.org/abs/2004.07219)\n",
    "\n",
    "[ MINARI: A dataset API for Offline Reinforcement Learning ](https://minari.farama.org/main/content/basic_usage/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "121px",
    "width": "195px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
