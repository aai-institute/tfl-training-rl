{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "813ba6c9",
   "metadata": {},
   "source": [
    "Final remarks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d216cf",
   "metadata": {},
   "source": [
    "Offline RL proves valuable in various scenarios, especially when:\n",
    "\n",
    "a. Robots require intelligent behavior in complex open-world environments demanding extensive training data due to robust visual perception requirements. (complex environment modeling and extensive data collection)\n",
    "\n",
    "b. Robot grasping tasks, which involve expert data that cannot be accurately simulated, providing an opportunity to assess our BCQ algorithm.\n",
    "\n",
    "c. Robotic navigation tasks, where offline RL aids in crafting effective navigation policies using real-world data.\n",
    "\n",
    "d. Autonomous driving, where ample expert data and an offline approach enhance safety.\n",
    "\n",
    "e. Healthcare applications, where safety is paramount due to the potential serious consequences of inaccurate forecasts.\n",
    "\n",
    "... and many more. \n",
    "\n",
    "However, if you have access to an environment with abundant data, online Reinforcement Learning (RL) can be a powerful choice due to its potential for exploration and real-time feedback. Nevertheless, the landscape of RL is evolving, and a data-centric approach is gaining prominence, exemplified by vast datasets like X-Embodiment. It's becoming evident that robots trained with diverse data across various scenarios tend to outperform those solely focused on specific tasks. Furthermore, leveraging multitask trained agents for transfer learning can be a valuable strategy for addressing your specific task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tianshou_dev",
   "language": "python",
   "name": "tianshou_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
