{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext training_rl\n",
    "%set_random_seed 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%presentation_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_latex_macros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"_static/images/aai-institute-cover.svg\" alt=\"Snow\" style=\"width:100%;\">\n",
    "<div class=\"md-slide title\">Recent Developments in Control Theory</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stochastic Optimal Control Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The methods discussed in this part deal with the problem of controlling dynamical systems\n",
    "that are subject to system constraints under uncertainty, which can affect numerous parts of the\n",
    "problem formulation. The system dynamics in discrete-time is given by:\n",
    "\n",
    "$$\n",
    "x_{k+1} = f_t(x_k, u_k, k, w_k, \\theta_t)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $x_k \\in \\mathbf{R}^n$ is the system state at time $k$.\n",
    "- $u_k \\in \\mathbf{R}^n$ is the applied input at time $k$.\n",
    "- $w_k$ describes a sequence of random variables corresponding to disturbances or process noise in the system, which are often assumed to be independent and identically distributed (i.i.d.).\n",
    "- $\\theta_t \\sim \\mathcal{Q}^{\\theta_t}$ is a random variable describing the parametric uncertainty of the system, which is therefore constant over time.\n",
    "- The subscript $t$ is used to emphasize that these quantities represent the true system dynamics or true optimal control problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The true problem therefore relates to the development of an optimal controller for a distribution of systems given by $\\mathcal{Q}^{\\theta_t}$ under random disturbances $w_k$.\n",
    "\n",
    "The optimality of the controller is defined with respect to a cost or objective function. In the\n",
    "presence of random model uncertainties, the cost is often defined as the expectation of a sum of\n",
    "potentially time-varying stage costs of the states and inputs over a possibly infinite horizon $N$:\n",
    "\n",
    "$$\n",
    "J_t = E\\left(\\sum \\limits_{k=0}^{N} g_t(x_k, u_k, k)\\right),\n",
    "$$\n",
    "\n",
    "where the expected value is taken with respect to all random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data-Driven Predictive Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Model predictive control (MPC) is an established control methodology that systematically uses forecasts to compute real-time optimal control decisions. In MPC, at each time step an optimization problem is solved over a moving horizon. The objective is to find a control policy that minimizes a predicted performance index while\n",
    "satisfying operating constraints.\n",
    "\n",
    "Uncertainty in MPC is handled by optimizing over multiple uncertain forecasts. In this case, performance index and\n",
    "operating constraints take the form of functions defined over a probability space, and the resulting technique is called stochastic MPC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stochastic Predictive Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Control Design Challenges\n",
    "\n",
    "- Ensuring recursive feasibility and achieving optimality despite a short prediction horizon.\n",
    "- Satisfying input and state constraints in the presence of uncertainty.\n",
    "- Ensuring computational tractability by properly reformulating constraints and costs and parameterizing control. policies\n",
    "\n",
    "There is no systematic and universal solution to the third challenge, and often the chosen approach is application dependent. Fortunately, the first and second challenges can be addressed by using data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##  Data-Driven Stochastic Predictive Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Model Predictive Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning-Based Model Predictive Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Learning-based MPC addresses the automated and data-driven generation or adaptation of el-\n",
    "ements of the MPC formulation such that the control performance with respect to the desired\n",
    "closed-loop system behavior—i.e., the general optimal control problem (Equation 4)—is im-\n",
    "proved. The setup in which this learning takes place can be diverse. For instance, offline learning\n",
    "considers the adaptation of the controller between different trials or episodes of a control task,\n",
    "during which data are collected. In methods that learn online, on the other hand, the controller is\n",
    "adjusted during closed-loop operation (e.g., while performing repetitive tasks) or using the data\n",
    "collected during one task execution.\n",
    "While much of the research in learning-based MPC is focusing on automatically improving the\n",
    "model quality, which is the most obvious component affecting MPC performance, several research\n",
    "efforts are addressing the formulation of the MPC problem directly or utilizing the MPC concept\n",
    "to satisfy constraints during learning-based control. In the remainder of the review, we discuss the\n",
    "research in the following three categories:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Learning the system dynamics\n",
    "\n",
    "MPC relies heavily on suitable and sufficiently accurate\n",
    "model representations of the system dynamics. One path of learning-based MPC considers\n",
    "the automatic adjustment of the system model, either during operation or between different\n",
    "operational instances. Section 3 provides an overview of this rather broad direction and\n",
    "related issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Many learning-based MPC techniques make use of an explicit distinction between a nominal\n",
    "system model $f_n$ and an additive learned term $f_l$ accommodating uncertainty:\n",
    "\n",
    "$$\n",
    "f(x, u, k, w, \\theta) = f_n(x, u, k) + f_l(x, u, k, w, \\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Learning the controller design\n",
    "\n",
    "A second interesting research direction focuses less on the\n",
    "prediction model and more on the remaining problem formulation, such as the employed\n",
    "cost function l, the constraints X , or the terminal components l f and X f , such that the\n",
    "resulting closed-loop MPC controller behaves favorably with respect to the underlying task,\n",
    "i.e., the stochastic optimal control problem. We discuss these approaches in Section 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MPC for safe learning\n",
    "\n",
    "A third direction is the use of MPC techniques to derive safety\n",
    "guarantees for learning-based controllers. The main idea is to decouple the optimization of\n",
    "the objective function lt from the requirement of constraint satisfaction, which is addressed\n",
    "using MPC techniques. We discuss this research direction in Section 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Safe Learning in Robotics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<figure>\n",
    "    <img src=\"_static/images/40_comparison_model_driven_data_driven.svg\" width=\"90%\"/>\n",
    "    <figcaption>\n",
    "        A comparison of model-driven, data-driven, and combined approaches.\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<figure>\n",
    "    <img src=\"_static/images/40_safe_control_block_diagram.svg\" width=\"80%\"/>\n",
    "    <figcaption>\n",
    "        Block diagram representing safe learning control approaches.\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Safety Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Safety level III: constraint satisfaction guaranteed.\n",
    "\n",
    "The system satisfies hard constraints:\n",
    "\n",
    "$$\n",
    "c_k^j(x_k, u_k, w_k) \\le 0\n",
    "$$\n",
    "\n",
    "for all times $k \\in \\{0, \\dots , N\\}$ and constraint indexes $j \\in \\{1, \\dots, n_c\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Safety level II: constraint satisfaction with high probability.\n",
    "\n",
    "The system satisfies probabilistic constraints:\n",
    "\n",
    "$$\n",
    "P\\left[c_k^j(x_k, u_k, w_k ) \\le 0 \\right] \\ge p^j,\n",
    "$$\n",
    "\n",
    "where $P[\\cdot]$ denotes the probability and $p^j \\in (0, 1)$ defines the likelihood of the jth constraint\n",
    "being satisfied, for all times $k \\in \\{0, \\dots , N\\}$ and constraint indexes $j \\in \\{1, \\dots, n_c\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Safety level I: constraint satisfaction encouraged\n",
    "\n",
    "The system encourages constraint satisfaction. This can be achieved in different ways:\n",
    "\n",
    "- One way is to add a penalty term to the objective function that discourages\n",
    "  the violation of constraints with a high cost. A non-negative $\\epsilon_j$ is added\n",
    "  to the right-hand side of the inequality in Safety level III, for all times $k \\in \\{0, \\dots , N\\}$\n",
    "  and constraint indexes $j \\in \\{1, \\dots, n_c\\}$:\n",
    "  \n",
    "  $$\n",
    "  c_k^j(x_k, u_k, w_k) \\le \\epsilon_j,\n",
    "  $$\n",
    "\n",
    "  and an appropriate penalty term l\u0003 (\u0002) ≥ 0, with l\u0003 (\u0002) = 0 ⇐⇒ \u0002 = 0, is added to the objective\n",
    "  function. The vector \u0002 includes all elements ϵj and is an additional variable of the optimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Another way is to provide guarantees on the expected value of the constraint but only at a trajectory level:\n",
    "\n",
    "  $$\n",
    "  J_{c^j} = E\\left[ \\sum\\limits_{k=0}^{N-1} c_k^j(x_k, u_k, w_k) \\right] \\le d_j,\n",
    "  $$\n",
    "\n",
    "  where $J_{c^j}$ represents the expected total constraint cost, and $d_j$ defines the constraint threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<figure>\n",
    "    <img src=\"_static/images/40_safety_levels.svg\" width=\"100%\"/>\n",
    "    <figcaption>\n",
    "        Illustration of Safety Levels.\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "<figure style=\"float: left; width: 70%;\">\n",
    "    <img src=\"_static/images/40_safe_learning_approaches.svg\" width=\"100%\"/>\n",
    "</figure>\n",
    "<div style=\"float: left; width: 20%;\">\n",
    "<br><br><br>Summary of safe learning control approaches.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell",
     "remove-cell-nbconv"
    ]
   },
   "source": [
    "<img src=\"_static/images/aai-institute-cover.svg\" alt=\"Snow\" style=\"width:100%;\">\n",
    "<div class=\"md-slide title\">Thank you for the attention!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "- [<b id=\"rosolia_datadriven_2018\">[Rosolia, U., Zhang, X. and Borrelli, F., 2018]</b>](#rosolia_datadriven_2018-back) Rosolia, Ugo, Xiaojing Zhang, and Francesco Borrelli. [Data-driven predictive control for autonomous systems.](https://www.annualreviews.org/doi/full/10.1146/annurev-control-060117-105215) Annual Review of Control, Robotics, and Autonomous Systems 1 (2018): 259-286.\n",
    "\n",
    "- [<b id=\"hewing_learningbased_2020\">[Hewing, Lukas, et al. 2020]</b>](#hewing_learningbased_2020-back) Hewing, Lukas, Kim P. Wabersich, Marcel Menner, and Melanie N. Zeilinger. [Learning-based model predictive control: Toward safe learning in control.](https://www.annualreviews.org/doi/full/10.1146/annurev-control-090419-075625) Annual Review of Control, Robotics, and Autonomous Systems 3 (2020): 269-296.\n",
    "\n",
    "- [<b id=\"brunke_safe_2022\">[Brunke, Lukas, et al. 2022]</b>](#brunke_safe_2022-back) Brunke, Lukas, Melissa Greeff, Adam W. Hall, Zhaocong Yuan, Siqi Zhou, Jacopo Panerati, and Angela P. Schoellig. [Safe learning in robotics: From learning-based control to safe reinforcement learning.](https://www.annualreviews.org/doi/abs/10.1146/annurev-control-042920-020211) Annual Review of Control, Robotics, and Autonomous Systems 5 (2022): 411-444."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "rise": {
   "footer": "<img src='_static/images/aai-logo.png' alt='logo' height='50em'>",
   "header": "<img src='_static/images/transferlab-logo.svg' alt='logo' height='20em' />",
   "theme": "white"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "148px",
    "width": "256px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "563.2px",
    "left": "125px",
    "top": "116.469px",
    "width": "315.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
