{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input",
     "remove-output",
     "remove-input-nbconv",
     "remove-output-nbconv"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext training_rl\n",
    "%set_random_seed 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%presentation_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_latex_macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import os\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Protocol\n",
    "\n",
    "import casadi\n",
    "import do_mpc\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from gymnasium import Env\n",
    "from IPython.display import HTML\n",
    "from ipywidgets import interact, widgets\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from training_rl.control import (\n",
    "    create_inverted_pendulum_environment,\n",
    "    create_mass_spring_damper_environment,\n",
    "    MassSpringDamperParameters,\n",
    "    InvertedPendulumParameters,\n",
    "    plot_inverted_pendulum_results,\n",
    "    create_shortest_path_graph,\n",
    "    plot_shortest_path_graph,\n",
    "    plot_all_paths_graph,\n",
    "    animate_mass_spring_damper_simulation,\n",
    "    animate_inverted_pendulum_simulation,\n",
    "    animate_full_inverted_pendulum_simulation,\n",
    "    display_array,\n",
    "    show_video,\n",
    ")\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "sns.set_theme()\n",
    "plt.rcParams[\"figure.figsize\"] = [9, 5]\n",
    "# This is needed because inside docker the rendering of mujoco environments doesn't work.\n",
    "render_mode = \"rgb_array\" if os.getlogin() != \"jovyan\" else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"_static/images/aai-institute-cover.svg\" alt=\"presentation first slide\" style=\"width:100%;\">\n",
    "<div class=\"md-slide title\">Control and Planning</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In previous sections, we have designed feedback controllers for various systems with the goal of regulating the system output to a desired setpoint. Specifically, we utilized Fullstate Feedback and PID controllers. While these simple controllers can effectively regulate many systems, they have limitations that prevent high performance control for more complex systems.\n",
    "\n",
    "First, these controllers have a fixed, static gain that does not change over time. This limits their ability to adapt to changing system dynamics or disturbances. Second, after developing a mathematical model of the system dynamics, we did not actually utilize the model in the controller design. A model-based approach could allow us to leverage our understanding of the system to improve control performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One ubiquitous challenge in control system design is the presence of control input constraints. Actuators in physical systems inherently have limits on their amplitude and rate of change. For example, a motor has maximum torque and acceleration limits. If control input constraints are ignored in the controller design, the resulting control inputs may saturate the actuators, degrading closed-loop performance.\n",
    "\n",
    "There are two main strategies to address control input constraints:\n",
    "\n",
    "- Reduce the performance requirements to levels achievable with a linear controller without violating the constraints.\n",
    "- Directly account for the constraints by modifying the control design and online optimization of the control input.   For example, model predictive control utilizes the system model to predict future behavior and optimize the control input while satisfying constraints.\n",
    "\n",
    "In subsequent sections, we will explore model-based and optimization-based control techniques to overcome the limitations of basic controllers. Properly managing control input constraints is crucial to achieving high performance in real control systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "<figure style=\"float: left; width: 60%;\">\n",
    "    <img src=\"_static/images/30_constrained_motion.png\" width=\"100%\"/>\n",
    "</figure>\n",
    "<div style=\"float: right; width: 39%;\">\n",
    "<br><br>Illustration of constrained motion of a car from point A to point B. There are state (position/velocity) constraints, and control (acceleration) constraints. When there are mobile obstacles, the state constraints may change unpredictably, necessitating on-line replanning.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this part of the training, we will move away from classical control methods and focus on optimal control methods applied to linear and non-linear systems.\n",
    "\n",
    "We will use the same 2 systems we have studied previously (Mass-Spring-Damper and Inverted Pendulum). We will additionally consider controlling the full non-linear inverted pendulum (pendulum angle and cart position).\n",
    "\n",
    "As we present the different methods, we will highlight commonalities and differences with Reinforcement Learning.\n",
    "\n",
    "For the final exercise we will attempt to control the highly non-linear inverted pendulum system with different objectives.\n",
    "\n",
    "Finally, we will present AlphaZero and highlight "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Planning refers to the explicit deliberation process that chooses and organizes actions by anticipating their\n",
    "outcomes with the goal to achieve some pre-stated objectives.\n",
    "\n",
    "Automated planning and scheduling, sometimes denoted as simply AI planning, is a branch of artificial intelligence that concerns the realization of strategies or action sequences, typically for execution by intelligent agents, autonomous robots and unmanned vehicles. Unlike classical control problems, the solutions are complex and must be discovered and optimized in multidimensional space.\n",
    "\n",
    "In planning we use a model of the environment/system to predict the effect of taking a certain action in a certain state. Thus it is a **model-based** approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### State-Transition Systems\n",
    "\n",
    "A state-transition system is a 3-tuple $\\Sigma = (S,A,\\gamma)$, where:\n",
    "\n",
    "- $S = \\{s_1,s_2,\\dots\\}$ is a finite or recursively enumerable set of states.\n",
    "- $U = \\{u_1,u_2,\\dots\\}$ is a finite or recursively enumerable set of actions.\n",
    "- $\\gamma: S\\times U \\rightarrow 2^S$ is a state transition function.\n",
    "\n",
    "- if $u \\in U$ and $\\gamma(s,u) \\neq \\emptyset$ then $a$ is applicable in $s$.\n",
    "\n",
    "- applying $u$ in $s$ will take the system to $s^{\\prime} \\in \\gamma(s,u).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A state-transition system can be represented by a directed labelled graph $G = (N_G,E_G)$ where:\n",
    "\n",
    "- the nodes correspond to the states in $S$, i.e. $N_G = S.$\n",
    "- there is an arc from $s \\in N_G$ to $s^\\prime \\in N_G$, i.e.$s \\rightarrow s^\\prime \\in E_G$, with label $u \\in U$ if and only if $s^\\prime \\in \\gamma(s,u).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Plans\n",
    "\n",
    "- a plan $\\pi$ is a finite sequence of actions, $\\pi = \\{u_1, \\dots, u_n\\}$\n",
    "- a planning problem is a triple $P = (\\Sigma, s_0, S_g)$, where $\\Sigma$ is a\n",
    "  state-transition system, $s_0 \\in S$ is an initial state, and $S_g \\subset S$ is a set of goal states.\n",
    "- each node is written as a pair $v = (\\pi, s)$ where $\\pi$ is a plan and $s = \\gamma(s_0, \\pi)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "<figure style=\"float: left; width: 30%;\">\n",
    "    <img src=\"_static/images/30_planning_and_plan_execution.png\" width=\"100%\"/>\n",
    "</figure>\n",
    "<div style=\"float: left; width: 60%;\">\n",
    "\n",
    "- Planner:\n",
    "  - given: description of an environment/system $\\Sigma$, initial state, and objective.\n",
    "  - generate: plan that achieves objective.\n",
    "- Controller:\n",
    "  - given: plan, current state (observation function: $\\eta:S \\rightarrow O$)\n",
    "  - generate: action.\n",
    "- Environment/System:\n",
    "  - evolves as actions are executed and events occur\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimal Control\n",
    "\n",
    "Optimal control theory is a branch of control theory that deals with finding a control for a dynamical system over a period of time such that an objective function is optimized. The fundamental idea in optimal control is to formulate the goal of control as the long-term optimization of a scalar cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<figure>\n",
    "    <img src=\"_static/images/30_optimal_control_problem.png\" width=\"100%\"/>\n",
    "    <figcaption>\n",
    "        Deterministic N-stage optimal control problem.\n",
    "    </figcaption>\n",
    "</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The optimal control problem is to find a control $u^* \\in \\mathbf{U}$ which causes the system $\\dot{x}(t) = f(x(t), u(t))$ to follow a trajectory $x^* \\in \\mathbf{X}$ that minimizes the cost (performance measure):\n",
    "\n",
    "\n",
    "### Continuous-time\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\displaystyle  \\min_{u} & J(x_0, u) & \\text{(cost)}\\\\\n",
    "\\text{subject to} & \\dot{x}(t) = f(x(t), u(t)) & \\text{(dynamical feasibility)}\\\\\n",
    "& x(T) \\in \\mathbf{X_T} & \\text{(boundary conditions)}\\\\\n",
    "& x(t) \\in \\mathbf{X} , \\forall t \\in [0, T] & \\text{(state constraints)}\\\\\n",
    "& u(t) \\in \\mathbf{U}, \\forall t \\in [0, T] & \\text{(input constraints)}\\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Discrete-time\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\displaystyle  \\min_{u} & J(x_0, u) & \\text{(cost)}\\\\\n",
    "\\text{subject to} & x_{t+1} = f(x_t, u_t) & \\text{(dynamical feasibility)}\\\\\n",
    "& x_N \\in \\mathbf{X_N} & \\text{(boundary conditions)}\\\\\n",
    "& x_t \\in \\mathbf{X} , \\forall t \\in \\{0, 1, \\dots , N - 1\\} & \\text{(state constraints)}\\\\\n",
    "& u_t \\in \\mathbf{U}, \\forall t \\in \\{0, 1, \\dots , N - 1\\} & \\text{(input constraints)}\\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Finite Horizon \n",
    "\n",
    "- Continuous-time:\n",
    "\n",
    "$$\n",
    "J_{0}(x_0, u) = g_T(x(T)) + \\int \\limits_{0}^{T} g(x(t), u(t)) dt\n",
    "$$\n",
    "\n",
    "- Discrete-time:\n",
    "\n",
    "$$\n",
    "J_0(x_0, u) = g_N(x_N) + \\sum \\limits_{k = 0}^{N-1} g_k(x_k, u_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Infinite Horizon\n",
    "\n",
    "- Continuous-time:\n",
    "\n",
    "$$\n",
    "J(x_0, u) = \\int \\limits_{0}^{\\infty} g(x(t), u(t)) dt\n",
    "$$\n",
    "\n",
    "- Discrete-time:\n",
    "\n",
    "$$\n",
    "J(x_0, u) = \\sum \\limits_{k = 0}^{\\infty} g_k(x_k, u_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<figure>\n",
    "    <img src=\"_static/images/30_transition_graph_discrete_system.png\" width=\"100%\"/>\n",
    "    <figcaption>\n",
    "        Transition graph for a deterministic discrete system.\n",
    "    </figcaption>\n",
    "</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This approach is powerful for a number of reasons. First and foremost, it is very general - allowing us to specify the goal of control equally well for fully- or under-actuated, linear or nonlinear, deterministic or stochastic, and continuous or discrete systems. Second, it permits concise descriptions of potentially very complex desired behaviours, specifying the goal of control as a scalar objective (plus a list of constraints)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Optimal control problems solving methods can be classified in three main families:\n",
    "Dynamic Programming (DP), Indirect Methods based on calculus of variation and Direct Methods.\n",
    "\n",
    "- DP is helpful where the number of states is limited and the dynamics are known. It divides an optimal control issue into smaller subproblems and recursively solves each.\n",
    "\n",
    "- Indirect methods rely on Pontryagin’s Minimum Principle (PMP) to derive the necessary conditions\n",
    "  for optimality. This method uses the Hamiltonian of the system to reduce the global optimal control problem\n",
    "  to the solution of a system of $2N$ equations given in the form of a two-point boundary value problem (BVP).  \n",
    "  Problems involving continuous states and control inputs benefit most from it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Direct methods rely on the discretization of the original optimal control problem which is then transcribed to\n",
    "  a nonlinear programming problem (NLP) solved numerically using a well-established optimisation method.\n",
    "  \n",
    "  There are many direct methods. They differ on how the variables (i.e. control and states) are discretised \n",
    "  and on how the continuous time dynamics is approximated.\n",
    "  \n",
    "  In the case of shooting and multiple shooting the control are parameterised\n",
    "  with piecewise linear functions and the differential equations\n",
    "  are solved via numerical integration. These approaches make use of robust\n",
    "  and available ordinary differential equations solvers\n",
    "  but need sensitivity analysis to compute the jacobians\n",
    "  of the continuity and boundary conditions with respect to the initial and intermediate conditions.\n",
    "\n",
    "  In the case of state and control parameterisation (direct collocation),\n",
    "  both states and controls are approximated with polynomial functions,\n",
    "  therefore the continuous time differential equations are converted into algebraic constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<figure>\n",
    "    <img src=\"_static/images/30_optimal_control_methods.svg\" width=\"80%\"/>\n",
    "    <figcaption>\n",
    "        Classification of different methods to solve optimal control problems and related formulations and\n",
    "solution algorithms <a id=\"biral_notes_2016-back\" href=\"#biral_notes_2016\">[Biral Notes 2016]</a>.\n",
    "    </figcaption>\n",
    "</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Choosing the cost function\n",
    "\n",
    "Choosing a cost function means translating the system's desired physical state into a mathematical formulation.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Minimum-time problems: $J = t_f - t_0$\n",
    "- Terminal control problems: $J = || x(t_f) - r(t_f) ||^2$\n",
    "- Minimum control-effort problems: $J = \\sum \\limits_{k = t_0}^{t_f} |u(t_k)|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Questions\n",
    "\n",
    "- What are possible cost functions for the 2 systems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mass-Spring-Damper Model\n",
    "\n",
    "\n",
    "<div>\n",
    "<figure style=\"float: left; width: 50%;\">\n",
    "    <img src=\"_static/images/20_mass_spring_damper.svg\" width=\"50%\"/>\n",
    "    <figcaption>\n",
    "        Classic model used for deriving the equations of a mass spring damper model <a href=\"#wiki_mass_spring_damper\"><b id=\"wiki_mass_spring_damper-back\">[Wiki Mass-Spring-Damper, 2023]</b></a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "<div style=\"float: left; width: 40%;\">\n",
    "    \n",
    "- $z(t)$: Distance along the vertical axis from some reference point.\n",
    "- $m$: Mass of the object.\n",
    "- $\\lambda$: Coefficient of elasticity.\n",
    "- $l$: Length of spring.\n",
    "- $k = \\frac{\\lambda}{l}$\n",
    "- $c$: Damping coefficient.\n",
    "- $f(t)$: Force applied on the object.\n",
    "- $\\gamma$: Motor's gear factor.\n",
    "- $g$: Gravity.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The system has linear state-space model with matrices:\n",
    "\n",
    "$$\n",
    "A\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "-\\frac{k}{m} & -\\frac{c}{m}\\\\\n",
    "\\end{bmatrix};\n",
    "B\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\frac{\\gamma}{m}\\\\\n",
    "\\end{bmatrix};\n",
    "C = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "\\end{bmatrix};\n",
    "D = \\begin{bmatrix}\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### State-Space Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "msd_parameters = MassSpringDamperParameters()\n",
    "# Dynamics matrix\n",
    "A = np.array(\n",
    "    [\n",
    "        [0, 1],\n",
    "        [-msd_parameters.k / msd_parameters.m, -msd_parameters.c / msd_parameters.m],\n",
    "    ]\n",
    ")\n",
    "# Input matrix\n",
    "B = np.array([[0, msd_parameters.gamma / msd_parameters.m]]).transpose()\n",
    "# Output matrices\n",
    "C = np.array([[1, 0], [0, 1]])\n",
    "D = np.zeros(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Model, States and Control inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mass_spring_damper = do_mpc.model.LinearModel(\"continuous\")\n",
    "mass_spring_damper.set_variable(var_type=\"_x\", var_name=\"position\")\n",
    "mass_spring_damper.set_variable(var_type=\"_x\", var_name=\"velocity\")\n",
    "mass_spring_damper.set_variable(var_type=\"_u\", var_name=\"force\")\n",
    "mass_spring_damper.setup(A, B, C, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "env = create_mass_spring_damper_environment()\n",
    "mass_spring_damper = mass_spring_damper.discretize(env.dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Inverted Pendulum Model\n",
    "\n",
    "\n",
    "<div>\n",
    "<figure style=\"float: left; width: 40%;\">\n",
    "    <img src=\"_static/images/20_inverted_pendulum.svg\" width=\"50%\"/>\n",
    "    <figcaption>\n",
    "        Inverted pendulum model <a href=\"#goodwin_control_2000\"><b id=\"goodwin_control_2000-back\">[Goodwin et al., 2000]</b></a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "    \n",
    "- $y(t)$: distance along the horizontal axis from some reference point.\n",
    "- $\\theta(t)$: angle of the pendulum.\n",
    "- $M$: mass of the cart.\n",
    "- $m$: mass of the pendulum (assumed to be concentrated at the tip).\n",
    "- $l$: length of the pendulum.\n",
    "- $\\mu_c$: cart friction coefficient.\n",
    "- $\\mu_p$: pendulum friction coefficient.\n",
    "- $f(t)$: force applied on the cart.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Linearized Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The system has the following partial (pendulum angle and angular velocity only) linearized (around $\\theta = 0$ and $\\dot{\\theta} = 0$) state space model:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "\\frac{(M + m)g}{Ml} & 0\\\\\n",
    "\\end{bmatrix};\n",
    "B = \\begin{bmatrix}\n",
    "0 \\\\ -\\frac{\\gamma}{Ml}\n",
    "\\end{bmatrix};\n",
    "C = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "\\end{bmatrix};\n",
    "D = \\begin{bmatrix}\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### State-Space Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "\n",
    "ip_parameters = InvertedPendulumParameters(\n",
    "    l=env.model.geom_pos[2, 2],\n",
    "    m=env.model.body_mass[2],\n",
    "    M=env.model.body_mass[1],\n",
    ")\n",
    "# Dynamics matrix\n",
    "A = np.array(\n",
    "    [\n",
    "        [0, 1],\n",
    "        [\n",
    "            (ip_parameters.M + ip_parameters.m)\n",
    "            * ip_parameters.g\n",
    "            / (ip_parameters.m * ip_parameters.l),\n",
    "            0,\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "# Input matrix\n",
    "B = np.array([[0, -ip_parameters.gamma / (ip_parameters.M * ip_parameters.l)]]).transpose()\n",
    "# Output matrices\n",
    "C = np.array([[1, 0], [0, 1]])\n",
    "D = np.zeros(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Model, States and Control inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum_lin = do_mpc.model.LinearModel(\"continuous\")\n",
    "theta = inverted_pendulum_lin.set_variable(var_type=\"_x\", var_name=\"theta\")\n",
    "dtheta = inverted_pendulum_lin.set_variable(var_type=\"_x\", var_name=\"dtheta\")\n",
    "inverted_pendulum_lin.set_variable(var_type=\"_u\", var_name=\"force\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Auxiliary Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We also define the pendulum's kinetic and potential energies:\n",
    "\n",
    "$E_{\\text{kinetic}} = \\frac{1}{2} m \\left( (l x_2 \\cos(x_1))^{2} + (l x_2 \\sin(x_1))^{2} \\right) + \\frac{1}{2}J x_2^2$\n",
    "    \n",
    "$E_{\\text{potential}} = m g  l \\cos(x_1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Inertia\n",
    "J = (ip_parameters.m * ip_parameters.l**2) / 3\n",
    "# Energies\n",
    "E_kin = 0.5 * J * dtheta**2 + 0.5 * ip_parameters.m * (\n",
    "    (ip_parameters.l * dtheta * casadi.cos(theta)) ** 2\n",
    "    + (ip_parameters.l * dtheta * casadi.sin(theta)) ** 2\n",
    ")\n",
    "E_pot = ip_parameters.m * ip_parameters.g * ip_parameters.l * casadi.cos(theta)\n",
    "inverted_pendulum_lin.set_expression(\"E_kinetic\", E_kin)\n",
    "inverted_pendulum_lin.set_expression(\"E_potential\", E_pot);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum_lin.setup(A, B, C, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "inverted_pendulum_lin = inverted_pendulum_lin.discretize(env.dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Non-Linear Model\n",
    "\n",
    "We also define the full non-linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Application of Newtonian physics to this system leads to the [following model](https://sharpneat.sourceforge.io/research/cart-pole/cart-pole-equations.html):\n",
    "\n",
    "$$\n",
    "\\ddot{y}(t) = \\frac{1}{m\\cos^2\\theta(t) - (1+k)(M+m)} \\left[\n",
    "mg\\sin\\theta(t)\\cos\\theta(t) - (1+k)(\\gamma f(t) + ml\\dot\\theta^2(t) \\sin\\theta(t) - \\mu_c \\dot{y}(t)) - \\cfrac{\\mu_p\\cos\\theta(t)}{l}\\dot{\\theta}(t)\n",
    "\\right]\\\\\n",
    "\\ddot\\theta(t) = \\frac{1}{(1+k)(M+m)l - ml\\cos^2\\theta(t)} \\left[\n",
    "(M+m)g\\sin\\theta(t) - \\cos\\theta(t) (\\gamma f(t) + ml\\dot\\theta^2(t)\\sin\\theta(t) - \\mu_c \\dot{y}(t)) - \\cfrac{(M+m)\\mu_p}{ml} \\dot{\\theta}(t)\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "with $k = \\frac{1}{3}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can convert this to state-space form with input $u(t) = f(t)$ and output\n",
    "$y(t)$; by introducing:\n",
    "\n",
    "$$\n",
    "X(t) = \\begin{bmatrix}\n",
    "x_1(t) \\\\ x_2(t) \\\\ x_3(t) \\\\ x_4(t)\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "y(t) \\\\ \\theta(t) \\\\ \\dot{y}(t) \\\\ \\dot{\\theta}(t) \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The system has the following full state-space model:\n",
    "\n",
    "$$\n",
    "\\dot{X}(t) = \\begin{bmatrix}\n",
    "\\dot{x_1}(t) \\\\ \\dot{x_2}(t) \\\\ \\dot{x_3}(t) \\\\ \\dot{x_4}(t)\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "x_2(t) \\\\\n",
    "x_4(t) \\\\\n",
    "\\frac{1}{m\\cos^2 x_2(t) - (1+k)(M+m)} \\left[\n",
    "mg\\sin x_2(t)\\cos x_2(t) - (1+k)(\\gamma u(t) + ml x_4^2(t) \\sin x_2(t) - \\mu_c x_3(t)) - \\cfrac{\\mu_p \\cos x_2(t)}{l} x_4(t)\n",
    "\\right]\\\\\n",
    "\\frac{1}{(1+k)(M+m)l - ml\\cos^2 x_2(t)} \\left[\n",
    "(M+m)g\\sin x_2(t) - \\cos x_2(t) (\\gamma u(t) + ml x_4^2(t)\\sin x_2(t) - \\mu_c x_3(t)) - \\cfrac{(M+m)\\mu_p}{ml} x_4(t)\n",
    "\\right]\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Model, States and Control inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum = do_mpc.model.Model(\"continuous\")\n",
    "\n",
    "pos = inverted_pendulum.set_variable(var_type=\"_x\", var_name=\"position\")\n",
    "theta = inverted_pendulum.set_variable(var_type=\"_x\", var_name=\"theta\")\n",
    "dpos = inverted_pendulum.set_variable(var_type=\"_x\", var_name=\"velocity\")\n",
    "dtheta = inverted_pendulum.set_variable(var_type=\"_x\", var_name=\"dtheta\")\n",
    "u = inverted_pendulum.set_variable(var_type=\"_u\", var_name=\"force\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "k = 1 / 3\n",
    "numerator = (\n",
    "    (ip_parameters.M + ip_parameters.m) * ip_parameters.g * casadi.sin(theta)\n",
    "    - casadi.cos(theta) * (\n",
    "        ip_parameters.gamma * u \n",
    "        + ip_parameters.m * ip_parameters.l * dtheta**2 * casadi.sin(theta)\n",
    "        - ip_parameters.mu_c * dpos\n",
    "    )\n",
    "    - (ip_parameters.M + ip_parameters.m) / (ip_parameters.m * ip_parameters.l) * ip_parameters.mu_p * dtheta\n",
    ")\n",
    "denominator = (\n",
    "    (1+k)*(ip_parameters.M + ip_parameters.m) * ip_parameters.l\n",
    "    - ip_parameters.m * ip_parameters.l * casadi.cos(theta) ** 2\n",
    ")\n",
    "ddtheta = numerator / denominator\n",
    "\n",
    "numerator = (\n",
    "    ip_parameters.m * ip_parameters.g * casadi.cos(theta) * casadi.sin(theta)\n",
    "    - (1+k)*(\n",
    "        ip_parameters.gamma * u\n",
    "        + ip_parameters.m * ip_parameters.l * dtheta**2 * casadi.sin(theta)\n",
    "        - ip_parameters.mu_c * dpos\n",
    "    )\n",
    "    - ip_parameters.mu_p * dtheta * casadi.cos(theta) / ip_parameters.l\n",
    ")\n",
    "denominator = ip_parameters.m * casadi.cos(theta)**2 - (1+k)*(ip_parameters.M + ip_parameters.m)\n",
    "ddpos = numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum.set_rhs(\"position\", dpos)\n",
    "inverted_pendulum.set_rhs(\"theta\", dtheta)\n",
    "inverted_pendulum.set_rhs(\"velocity\", ddpos)\n",
    "inverted_pendulum.set_rhs(\"dtheta\", ddtheta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Auxiliary Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And kinetic and potential energies:\n",
    "\n",
    "$E_{\\text{kinetic}} = E_{\\text{kinetic, cart}} + E_{\\text{kinetic, pendulum}}$\n",
    "    \n",
    "$E_{\\text{kinetic, cart}} = \\frac{1}{2} M x_3^{2}$\n",
    "    \n",
    "$E_{\\text{kinetic, pendulum}} = \\frac{1}{2} m \\left( (x_3 + l x_4 \\cos(x_2))^{2} + (l x_4 \\sin(x_2))^{2} \\right) + \\frac{1}{2} J x_4$\n",
    "    \n",
    "$E_{\\text{potential}} = m g  l \\cos(x_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Inertia\n",
    "J = (ip_parameters.m * ip_parameters.l**2) / 3\n",
    "# Energies\n",
    "E_kin = (\n",
    "    0.5 * J * dtheta**2\n",
    "    + 0.5 * ip_parameters.M * dpos**2\n",
    "    + 0.5\n",
    "    * ip_parameters.m\n",
    "    * (\n",
    "        (dpos + ip_parameters.l * dtheta * casadi.cos(theta)) ** 2\n",
    "        + (ip_parameters.l * dtheta * casadi.sin(theta)) ** 2\n",
    "    )\n",
    ")\n",
    "E_pot = ip_parameters.m * ip_parameters.g * ip_parameters.l * casadi.cos(theta)\n",
    "inverted_pendulum.set_expression(\"E_kinetic\", E_kin)\n",
    "inverted_pendulum.set_expression(\"E_potential\", E_pot);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class FeedbackController(Protocol):\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        ...\n",
    "\n",
    "\n",
    "class ConstantController:\n",
    "    def __init__(self, u: float) -> None:\n",
    "        self.u = np.asarray([u])\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return self.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EnvironmentSimulationResults:\n",
    "    frames: list[NDArray]\n",
    "    observations: NDArray\n",
    "    actions: NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def simulate_environment(\n",
    "    env: Env,\n",
    "    *,\n",
    "    controller: FeedbackController,\n",
    "    max_steps: int = 500,\n",
    ") -> EnvironmentSimulationResults:\n",
    "    if controller is None:\n",
    "        controller = RandomController(env)\n",
    "\n",
    "    observation, _ = env.reset()\n",
    "    actions = []\n",
    "    observations = [observation]\n",
    "    frames = []\n",
    "\n",
    "    for _ in range(max_steps):\n",
    "        action = controller.act(observation)\n",
    "        observation, _, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "        observations.append(observation)\n",
    "        actions.append(action)\n",
    "\n",
    "        # Check if we need to stop the simulation\n",
    "        if terminated or truncated:\n",
    "            if env.render_mode is not None:\n",
    "                frames = env.render()\n",
    "            env.reset()\n",
    "            break\n",
    "    env.close()\n",
    "\n",
    "    actions = np.stack(actions)\n",
    "    observations = np.stack(observations)\n",
    "\n",
    "    return EnvironmentSimulationResults(\n",
    "        frames=frames,\n",
    "        observations=observations,\n",
    "        actions=actions,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Simulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_mass_spring_damper_environment()\n",
    "mass_spring_damper_simulator = do_mpc.simulator.Simulator(mass_spring_damper)\n",
    "mass_spring_damper_simulator.set_param(t_step=env.dt)\n",
    "mass_spring_damper_simulator.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "inverted_pendulum_lin_simulator = do_mpc.simulator.Simulator(inverted_pendulum_lin)\n",
    "inverted_pendulum_lin_simulator.set_param(t_step=env.dt)\n",
    "inverted_pendulum_lin_simulator.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment(cutoff_angle=np.inf)\n",
    "inverted_pendulum_simulator = do_mpc.simulator.Simulator(inverted_pendulum)\n",
    "params_simulator = {\n",
    "    # Note: cvode doesn't support DAE systems.\n",
    "    \"integration_tool\": \"idas\",\n",
    "    \"abstol\": 1e-8,\n",
    "    \"reltol\": 1e-8,\n",
    "    \"t_step\": env.dt,\n",
    "}\n",
    "inverted_pendulum_simulator.set_param(**params_simulator)\n",
    "inverted_pendulum_simulator.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dynamic Programming\n",
    "\n",
    "Dynamic programming (DP) is a method that in general solves optimization problems that involve making a sequence of decisions by determining, for each decision, subproblems that can be solved in like fashion, such that an optimal\n",
    "solution of the original problem can be found from optimal solutions of sub-\n",
    "problems. This method is based on Bellman’s Principle of Optimality, which\n",
    "he phrased as follows:\n",
    "\n",
    "> An optimal policy has the property that whatever the initial state and\n",
    "initial decision are, the remaining decisions must constitute an optimal\n",
    "policy with regard to the state resulting from the first decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<figure>\n",
    "    <img src=\"_static/images/30_optimality_principle.png\"/>\n",
    "</figure>\n",
    "\n",
    "Schematic illustration of the principle of optimality. The tail $\\{u_k^∗, \\dots, u_{N-1}^*\\}$ of an optimal sequence $\\{u_0^∗, \\dots, u_{N-1}^*\\}$ is optimal for the tail subproblem that starts at the state $x_k^*$ of the optimal state trajectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dynamic Programming is a very general solution method for problems which have two properties:\n",
    "\n",
    "- Optimal substructure (Principle of optimality applies)\n",
    "  - Optimal solution can be decomposed into subproblems, e.g., shortest path\n",
    "- Overlapping subproblems\n",
    "  - Subproblems recur many times\n",
    "  - Solutions can be cached and reused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dynamic programming is used across a wide variety of domains, e.g.\n",
    "\n",
    "- Scheduling algorithms\n",
    "- Graph algorithms (e.g., shortest path algorithms)\n",
    "- Graphical models in ML (e.g., Viterbi algorithm)\n",
    "- Bioinformatics (e.g., Sequence alignment, Protein folding) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We define the **cost-to-go function** (also known as **optimal value function**) as (for the sake of simplicity we will focus on the discrete-time case):\n",
    "\n",
    "$$\n",
    "V_0(x_0) := \\min_{u \\in \\mathbf{U}} J_0(x_0, u)\n",
    "$$\n",
    "\n",
    "An admissible control sequence $u^*$ is called optimal, if\n",
    "\n",
    "$$\n",
    "V_0(x_0) = J_0(x_0, u^*)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For any feasible $x_0 \\in \\mathbf{X}$ the optimal value function satisfies\n",
    "\n",
    "$$\n",
    "V_k(x_0) = \\displaystyle \\min_{u \\in \\mathbf{U}} g_{k}(x_0, u) + V_{k+1}(f(x_0, u))\n",
    "$$\n",
    "\n",
    "Moreover, if $u^*$ is an optimal control, then\n",
    "\n",
    "$$\n",
    "V_0(x_0) = g_{k}(x_0, u) + V_{k+1}(f(x_0, u))\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "V_0(x_0) = J_0(x_0, u^*)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  DP Algorithm\n",
    "\n",
    "For every initial state $x_0$, the optimal cost is equal to $V_N(x_0)$, given by the last step of the following algorithm, which proceeds backward in time from stage $N-1$ to stage $0$:\n",
    "\n",
    "- Start with $V_N(x_N) = g_N(x_N)$\n",
    "- then for $k = \\{0, \\dots , N - 1\\}$, let:\n",
    " \n",
    "  $$\n",
    "  V_{k}(x_{k}) = \\displaystyle \\min_{u \\in \\mathbf{U}} \\left\\{ g_{k}(x_{k}, u_{k}) + V_{k+1}(f(x_{k}, u_{k})) \\right\\}\n",
    "  $$\n",
    "  \n",
    "Once the functions $V_0, \\dots , V_N$ have been obtained, we can use a forward algorithm to construct an optimal control sequence $\\{u_0^*, \\dots, u_{N-1}^*\\}$ and corresponding state trajectory $\\{x_1^∗, \\dots, x_{N}^*\\}$ for the given initial state $x_0$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "<figure>\n",
    "    <img src=\"_static/images/30_dynamic_programming.png\" width=\"%80\"/>\n",
    "</figure>\n",
    "\n",
    "Illustration of the DP algorithm. The tail subproblem that starts at $x_k$ at time $k$ minimizes over\n",
    "$\\{u_k , \\dots , u_{N-1}\\}$ the \"cost-to-go\" from $k$ to $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "G = create_shortest_path_graph()\n",
    "plot_shortest_path_graph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We wish to travel from node A to node G at minimum cost. If the cost represents time then we want to find the shortest path from A to G.\n",
    "\n",
    "- Arrows (edges) indicate the possible movements.\n",
    "- Numbers on edges indicate the cost of moving along an edge.\n",
    "\n",
    "Use Dynamic Programming to solve this problem.\n",
    "\n",
    "> **Hint** Determine all possible paths first and then compute the cost-to-go at each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "plot_all_paths_graph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "source": [
    "Each node in this new graph represents a state. We will start from the tail (the last states) and compute recursively the cost for each state transition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "We start by determining the cost-to-go for all positions.\n",
    "\n",
    "Let $l(n_1, n_2)$ the cost of going from node $n_1$ to $n_2$ and $V(n)$ be the cost-to-go from node $n$.\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V(\\text{ABDF}) &= g(\\text{ABDF}, \\text{ABDFG}) &= 1\\\\\n",
    "V(\\text{ABE}) &= g(\\text{ABE}, \\text{ABEG}) &= 4\\\\\n",
    "V(\\text{ACF}) &= g(\\text{ACF}, \\text{ACFG}) &= 1\\\\\n",
    "V(\\text{ADF}) &= g(\\text{ADF}, \\text{ADFG}) &= 1\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V(\\text{ABD}) &= \\min \\left[ g(\\text{ABD}, \\text{ABDG}), g(\\text{ABD}, \\text{ABDF}) + V(\\text{ABDF}) \\right]\n",
    "&= \\min \\left[ 8, 5 + 1 \\right] &= 6\n",
    "\\\\\n",
    "V(\\text{AB}) &= \\min \\left[ g(\\text{AB}, \\text{ABD}) + V(\\text{ABD}), g(\\text{AB}, \\text{ABE}) + V(\\text{ABE}) \\right]\n",
    "&= \\min \\left[ 9 + 6, 1 + 4 \\right] &= 5\n",
    "\\\\\n",
    "V(\\text{AC}) &= g(\\text{AC}, \\text{ACF}) + V(\\text{ACF}) &= 2 + 1 &= 3\n",
    "\\\\\n",
    "V(\\text{AD}) &= \\min \\left[ g(\\text{AD}, \\text{ADF}) + V(\\text{ADF}), g(\\text{AD}, \\text{ADG})) \\right]\n",
    "&= \\min \\left[ 5 + 1, 8 \\right] &= 6\n",
    "\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V(\\text{A}) &= \\min \\left[\n",
    "g(\\text{A}, \\text{AB}) + V(\\text{AB}), g(\\text{A}, \\text{AC}) + V(\\text{AC}), g(\\text{A}, \\text{AD}) + V(\\text{AD})\n",
    "\\right]\n",
    "&= \\min \\left[ 1 + 5, 5 + 3, 3 + 6 \\right] &= 6\n",
    "\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The shortest-path is ABEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "plot_all_paths_graph(G, show_solution=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Quadratic Regulator\n",
    "\n",
    "While solving the optimal control problem (OCP) is very hard in general, there are a few very important special cases where the solutions are very accessible. Most of these involve variants on the case of linear dynamics and quadratic cost. The simplest case, called the linear quadratic regulator (LQR), is formulated as stabilizing a time-invariant linear system to the origin can be solved analytically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a discrete-time linear system described by:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t+1} = A \\mathbf{x}_t + B \\mathbf{u}_t\n",
    "$$\n",
    "\n",
    "where $x\\in \\mathbb {R} ^{n}$ (that is, $x$ is an $n$-dimensional real-valued vector) is the state of the system and $u\\in \\mathbb {R} ^{m}$ is the control input. Given a quadratic cost function for the system in the infinite-horizon case, defined as:\n",
    "\n",
    "$$\n",
    "J(\\mathbf{x}_0, \\mathbf{u}) = \\sum \\limits _{k = 0}^{\\infty} \\mathbf{x}_k^{T}Q \\mathbf{x}_k + \\mathbf{u}_k^{T} R \\mathbf{u}_k\n",
    "$$\n",
    "\n",
    "With $Q = Q^T \\succeq 0$, $R = R^T \\succeq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In both cases, the control law that minizes the cost is given by:\n",
    "\n",
    "$$\n",
    "u_k = -K x_k\n",
    "$$\n",
    "\n",
    "With: $K = (R + B^T P B)^{-1} B^T P B$\n",
    "\n",
    "and $P$ is found by solving the discrete time algebraic Riccati equation (DARE):\n",
    "\n",
    "$$\n",
    "Q + A^{T}PA-(A^{T}PB)(R+B^{T}PB)^{-1}(B^{T}PA) = P.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<figure>\n",
    "    <img src=\"_static/images/30_lqr_block_diagram.svg\" width=\"60%\"/>\n",
    "    <figcaption>\n",
    "        LQR Block Diagram.\n",
    "    </figcaption>\n",
    "</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mass-Spring-Damper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we design Linear Quadratic Regulator for the Mass-Spring-Damper model. First, we create an instance of the LQR class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lqr = do_mpc.controller.LQR(mass_spring_damper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We choose an infinite prediction horizon (`n_horizon = None`), the time step `t_step = 0.04s` second (which is the same as the environment's timestep)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_mass_spring_damper_environment(render_mode=render_mode)\n",
    "lqr.settings.t_step = env.dt\n",
    "lqr.settings.n_horizon = None  # infinite horizon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The goal is to drive the Mass-Spring-Damper system to the desired position. For that we define the following objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Q = np.diag([1000, 0])\n",
    "R = np.diag([0])\n",
    "display_array(\"Q\", Q)\n",
    "display_array(\"R\", R)\n",
    "lqr.set_objective(Q=Q, R=R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We then complete the LQR setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lqr.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, we set the desired setpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "xss = np.array([0.1, 0.0]).reshape(-1, 1)\n",
    "lqr.set_setpoint(xss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### SImulation\n",
    "\n",
    "Now, we simulate the closed-loop system for 50 steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lqr.reset_history()\n",
    "mass_spring_damper_simulator.reset_history()\n",
    "x0 = np.zeros((2, 1))\n",
    "mass_spring_damper_simulator.x0 = x0\n",
    "for _ in range(50):\n",
    "    u0 = lqr.make_step(x0)\n",
    "    x0 = mass_spring_damper_simulator.make_step(u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "animate_mass_spring_damper_simulation(lqr.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Evaluation\n",
    "\n",
    "Finally, we evaluate the controller on the actual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class LQRController:\n",
    "    def __init__(self, lqr: do_mpc.controller.LQR) -> None:\n",
    "        self.lqr = lqr\n",
    "        self.lqr.reset_history()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return lqr.make_step(observation.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "max_steps = 100\n",
    "env = create_mass_spring_damper_environment(render_mode=render_mode, max_steps=max_steps)\n",
    "controller = LQRController(lqr)\n",
    "results = simulate_environment(env, max_steps=max_steps, controller=controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "show_video(results.frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, ax, graphics = do_mpc.graphics.default_plot(lqr.data)\n",
    "ax[0].hlines(xss[0], lqr.data._time[0], lqr.data._time[-1], \"r\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "- Change the cost matrices of the LQR problem above and try to find the best combinations. \n",
    "- Design an LQR controller for the inverted pendulum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "### Inverted Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "lqr = do_mpc.controller.LQR(inverted_pendulum_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "lqr.settings.t_step = env.dt\n",
    "lqr.settings.n_horizon = None  # infinite horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# Setting the objective\n",
    "Q = np.diag([100, 1])\n",
    "R = np.diag([10])\n",
    "display_array(\"Q\", Q)\n",
    "display_array(\"R\", R)\n",
    "lqr.set_objective(Q=Q, R=R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "lqr.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# Define set point\n",
    "xss = np.array([0.0, 0.0]).reshape(-1, 1)\n",
    "lqr.set_setpoint(xss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "lqr.reset_history()\n",
    "inverted_pendulum_lin_simulator.reset_history()\n",
    "x0 = np.zeros((2, 1))\n",
    "x0[0] = 0.01\n",
    "inverted_pendulum_lin_simulator.x0 = x0\n",
    "for k in range(50):\n",
    "    u0 = lqr.make_step(x0)\n",
    "    x0 = inverted_pendulum_lin_simulator.make_step(u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "animate_inverted_pendulum_simulation(lqr.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "class LQRController:\n",
    "    def __init__(self, lqr: do_mpc.controller.LQR) -> None:\n",
    "        self.lqr = lqr\n",
    "        self.lqr.reset_history()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return lqr.make_step(observation[[1, 3]].reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "max_steps = 500\n",
    "env = create_inverted_pendulum_environment(render_mode=render_mode, max_steps=max_steps)\n",
    "controller = LQRController(lqr)\n",
    "results = simulate_environment(env, max_steps=max_steps, controller=controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "show_video(results.frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, ax, graphics = do_mpc.graphics.default_plot(lqr.data, aux_list=[])\n",
    "ax[0].hlines(xss[0], lqr.data._time[0], lqr.data._time[-1], \"r\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Predictive Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Unfortunately, the analytically convenient linear quadratic problem formulations are often not satisfactory. There are two main reasons for this:\n",
    "\n",
    "- The system may be nonlinear, and it may be inappropriate to use for\n",
    "  control purposes. Moreover, some of the control variables may be naturally\n",
    "  discrete, and this is incompatible with the linear system viewpoint.\n",
    "  \n",
    "- There may be control and/or state constraints, which are not handled\n",
    "  adequately through quadratic penalty terms in the cost function. For\n",
    "  example, the motion of a car may be constrained by the presence of\n",
    "  obstacles and hardware limitations.\n",
    "  The solution obtained from a linear quadratic model may not be suitable for such\n",
    "  a problem, because quadratic penalties treat constraints \"softly\"\n",
    "  and may produce trajectories that violate the constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Model Predictive Control (MPC) is a control algorithm based on solving an **on-line** optimal control problem. A receding horizon approach is used which can be summarized in the following steps:\n",
    "\n",
    "1. At time $t$ and for the current state $x_t$, solve, on-line, an open-loop optimal control problem over some future interval taking account the current and future constraints.\n",
    "2. Apply the first step in the optimal control sequence.\n",
    "3. Repeat the procedure at time $t + 1$ using the current state $x_{t + 1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "<figure style=\"float: left; width: 60%;\">\n",
    "    <img src=\"_static/images/30_model_predictive_control_horizon.svg\" width=\"100%\"/>\n",
    "</figure>\n",
    "<div style=\"float: right; width: 39%;\">\n",
    "<br><br><br>Illustration of the problem solved by MPC at state $x_k$.\n",
    "We minimize the cost function over the next $l$ stages.\n",
    "We then apply the control of the optimizing sequence up to the control horizon.\n",
    "In most cases, the control horizon is set to 1.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<figure>\n",
    "    <img src=\"_static/images/30_mpc_block_diagram.svg\" width=\"80%\"/>\n",
    "    <figcaption>\n",
    "        MPC Block Diagram.\n",
    "    </figcaption>\n",
    "</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A major difference between MPC and finite-state stochastic control problems\n",
    "that are popular in the RL/artificial intelligence literature is that in MPC\n",
    "the state and control spaces are continuous/infinite, such as for example\n",
    "in self-driving cars, the control of aircraft and drones, or the operation of\n",
    "chemical processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Iterative Linear Quadratic Regulator\n",
    "\n",
    "Iterative Linear Quadratic Regulator (iLQR) is an extension of LQR control to non-linear system with non-linear quadratic costs.\n",
    "\n",
    "The idea is to approximate the cost and dynamics as quadratic and affine, respectively, then exactly solve the resulting LQR problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given a discrete-time non-linear system with state-space representation: \n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t+1} = f(\\mathbf{x}_t, \\mathbf{u}_t)\n",
    "$$\n",
    "\n",
    "we approximate it with a first-order Taylor-series expansion about nominal trajectories\n",
    "$\\mathbf{X} = \\{\\mathbf{x}_0, \\dots, \\mathbf{x}_N\\}, \\mathbf{U} = \\{ \\mathbf{u}_0, \\dots, \\mathbf{u}_N \\}$:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\mathbf{x}_{t+1} + \\delta\\mathbf{x}_{t+1} &= f(\\mathbf{x}_t + \\delta \\mathbf{x}_t, \\mathbf{u}_t + \\delta \\mathbf{u}_t) \\\\ \n",
    "& \\approx f(\\mathbf{x}_t, \\mathbf{u}_t)\n",
    "+ \\frac{\\partial f}{\\partial \\mathbf{x}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{x}_t\n",
    "+ \\frac{\\partial f}{\\partial \\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{u}_t\\\\\n",
    "\\delta\\mathbf{x}_{t+1} &= A_t\\delta\\mathbf{x}_t + B_t\\delta\\mathbf{u}_t\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$\n",
    "A_t = A(\\mathbf{x}_t, \\mathbf{u}_t) = \\frac{\\partial f}{\\partial \\mathbf{x}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\\\\n",
    "B_t = B(\\mathbf{x}_t, \\mathbf{u}_t) = \\frac{\\partial f}{\\partial \\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given a general cost function that is not linear-quadratic, we use a second-order Taylor Series Expansion to linearize the dynamics into a form common for optimal control problems:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "J_N(\\mathbf{x}_0, \\mathbf{U}) &=\n",
    "l_f(\\mathbf{x}_N) + \\sum \\limits_{t=1}^{N-1} l(\\mathbf{x}_t, \\mathbf{u}_t)\\\\\n",
    "&\\approx \\frac{1}{2} \\mathbf{x}^T_N Q \\mathbf{x}_N + q_N^T \\mathbf{x}_N\n",
    "+ \\sum \\limits_{t=1}^{N-1}\n",
    "\\frac{1}{2} \\mathbf{x}^T_t Q_t \\mathbf{x}_t\n",
    "+ \\frac{1}{2} \\mathbf{u}^T_t R_t \\mathbf{u}_t\n",
    "+ \\frac{1}{2} \\mathbf{x}^T_t H_t \\mathbf{u}_t\n",
    "+ \\frac{1}{2} \\mathbf{u}^T_t H_t^T \\mathbf{x}_t\n",
    "+ q_t^T \\mathbf{x}_t +  + r_t^T \\mathbf{u}_t\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We define the following variables for convenience:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "l_x &:= \\frac{\\partial l}{\\partial \\mathbf{x}}|_{\\mathbf{x}_t, \\mathbf{u}_t} = Q_t \\mathbf{x}_t + q_t\n",
    "\\\\\n",
    "l_u &:= \\frac{\\partial l}{\\partial \\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t} = R_t \\mathbf{u}_t + r_t\n",
    "\\\\\n",
    "l_{xx} &:= \\frac{\\partial^2 l}{\\partial \\mathbf{x}^2}|_{\\mathbf{x}_t, \\mathbf{u}_t} = Q_t\n",
    "\\\\\n",
    "l_{uu} &:= \\frac{\\partial^2 l}{\\partial \\mathbf{u}^2}|_{\\mathbf{x}_t, \\mathbf{u}_t} = R_t\n",
    "\\\\\n",
    "l_{xu} &:= \\frac{\\partial^2 l}{\\partial \\mathbf{x}\\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t} = H_t\n",
    "\\\\\n",
    "l_{ux} &:= \\frac{\\partial^2 l}{\\partial \\mathbf{u}\\mathbf{x}}|_{\\mathbf{x}_t, \\mathbf{u}_t} = H_t^T\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can apply Bellman's Principle of Optimality to define the optimal cost-to-go:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V_N(\\mathbf{x}_N) &= g_f(\\mathbf{x}_N)\\\\\n",
    "V_{t}(\\mathbf{x}_t) &= \\displaystyle \\min_u {g(\\mathbf{x}_{t}, \\mathbf{u}_{t}) + V_{t+1}(f(\\mathbf{x}_{t}, \\mathbf{u}_{N-t}))}\\\\\n",
    "V_{t}(\\mathbf{x}_t) &= \\displaystyle \\min_u Q_{t}(\\mathbf{x}_{t}, \\mathbf{u}_{t})\n",
    "\\end{array}\\\\\n",
    "$$\n",
    "\n",
    "The $Q$-function is the discrete-time analogue of the Hamiltonian, sometimes known as the pseudo-Hamiltonian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We approximate the cost-to-go function as locally quadratic near the nominal trajectory gives us (we drop the time index in some of the equations for the sake of readability):\n",
    "\n",
    "$$\n",
    "\\delta V(\\mathbf{x}) = s^T \\delta\\mathbf{x} + \\frac{1}{2} \\delta\\mathbf{x}^T S \\delta\\mathbf{x}\n",
    "$$\n",
    "\n",
    "with \n",
    "$s = \\frac{\\partial V}{\\partial \\mathbf{x}}|_{\\mathbf{x}},\n",
    "S = \\frac{\\partial^2 V}{\\partial \\mathbf{x}^2}|_{\\mathbf{x}}$\n",
    "\n",
    "Similarily:\n",
    "\n",
    "$$\n",
    "\\delta Q(\\mathbf{x}, \\mathbf{u}) = \n",
    "\\frac{1}{2}\n",
    "\\begin{bmatrix} \\delta\\mathbf{x} \\\\ \\delta\\mathbf{u} \\end{bmatrix}^T\n",
    "\\begin{bmatrix} Q_{xx} & Q_{xu} \\\\ Q_{ux} & Q_{uu} \\end{bmatrix}\n",
    "\\begin{bmatrix} \\delta\\mathbf{x} \\\\ \\delta\\mathbf{u} \\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix} Q_{x} \\\\ Q_{u} \\end{bmatrix}^T\n",
    "\\begin{bmatrix} \\delta\\mathbf{x} \\\\ \\delta\\mathbf{u} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "Q_x &= l_x + s_{t+1} A_t \\\\\n",
    "Q_u &= l_u + s_{t+1} B_t \\\\\n",
    "Q_{xx} &= l_{xx} + A_t^T S_{t+1} A_t \\\\\n",
    "Q_{uu} &= l_{uu} + B_t^T S_{t+1} B_t \\\\\n",
    "Q_{ux} &= l_{ux} + B_t^T S_{t+1} A_t\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The optimal control modification $\\delta\\mathbf{u}^∗$ for some state perturbation $\\delta\\mathbf{x}$, is obtained by minimizing the quadratic model:\n",
    "\n",
    "$$\n",
    "\\delta\\mathbf{u}^∗(\\delta\\mathbf{x}) = \\displaystyle\\arg\\min_{\\delta\\mathbf{u}} Q(\\delta\\mathbf{x}, \\delta\\mathbf{u}) = k + K\\delta\\mathbf{x}\n",
    "$$\n",
    "\n",
    "This is a locally-linear feedback policy with:\n",
    "\n",
    "$$\n",
    "k := -Q_{uu}^{-1}Q_u\\\\\n",
    "K := -Q_{uu}^{-1}Q_{ux}\n",
    "$$\n",
    "\n",
    "Plugging this back into the expansion of $Q$, a quadratic model of $V$ is obtained. After simplification it is:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\Delta V &= \\frac{1}{2} k^T Q_{uu} k + k^T Q_u\\\\\n",
    "s &= Q_x + K^T Q_{uu} k + K^T Q_u + Q_{ux}^T k\\\\\n",
    "S &= Q_{xx} + K^T Q_{uu} K + K^T Q_{ux} + Q_{ux}^T K\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Once these terms are computed, a forward pass computes a new trajectory:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\hat{x}_0 &= x_0\\\\\n",
    "\\hat{u}_t &= u_t + k_t + K_t(\\hat{x}_t - x_t)\\\\\n",
    "\\hat{x}_{t+1} &= f(\\hat{x}_t, \\hat{u}_t)\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The basic flow of the algorithm is:\n",
    "\n",
    "1. Initialize with initial state $\\mathbf{x}_0$ and initial control sequence $\\mathbf{U} = \\{\\mathbf{u}_{0}, \\mathbf{u}_{1}, \\dots, \\mathbf{u}_{N-1}\\}$.\n",
    "2. Do a forward pass using the non-linear dynamics, i.e. simulate the system using $(\\mathbf{x}_0, \\mathbf{U})$ to get the trajectory through state space, $\\mathbf{X}$, that results from applying the control sequence $\\mathbf{X}$ starting in $\\mathbf{x}_0$.\n",
    "3. Do a backward pass, estimate the value function and dynamics for each $(\\mathbf{x}, \\mathbf{u})$ in the state-space and control signal trajectories.\n",
    "4. Calculate an updated control signal $\\hat{\\mathbf{U}}$ and evaluate cost of trajectory resulting from $(\\mathbf{x}_0, \\hat{\\mathbf{U}})$.\n",
    "   \n",
    "   1. If $|(\\textrm{cost}(x_0, \\hat{\\textbf{U}}) - \\textrm{cost}(x_0, \\textbf{U})| < \\textrm{threshold},$ then we've converged and exit.\n",
    "   2. If $\\textrm{cost}(x_0, \\hat{\\textbf{U}}) < \\textrm{cost}(x_0, \\textbf{U}),$ then set $\\textbf{U} = \\hat{\\textbf{U}},$ and change the update size to be more aggressive. Go back to step 2.\n",
    "   3. If $\\textrm{cost}(x_0, \\hat{\\textbf{U}}) \\geq \\textrm{cost}(x_0, \\textbf{U}),$ change the update size to be more modest. Go back to step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Differential Dynamic Programming\n",
    "\n",
    "Differential Dynamic Programming (DDP) is almost identical to iLQR but unlike the latter, it expands the system's dynamics to the second order i.e. for a given a discrete-time non-linear system with state-space representation: \n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t+1} = f(\\mathbf{x}_t, \\mathbf{u}_t)\n",
    "$$\n",
    "\n",
    "we approximate it with a **second-order** Taylor-series expansion about nominal trajectories\n",
    "$\\mathbf{X} = \\{\\mathbf{x}_0, \\dots, \\mathbf{x}_N\\}, \\mathbf{U} = \\{ \\mathbf{u}_0, \\dots, \\mathbf{u}_N \\}$:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\mathbf{x}_{t+1} + \\delta\\mathbf{x}_{t+1} &= f(\\mathbf{x}_t + \\delta \\mathbf{x}_t, \\mathbf{u}_t + \\delta \\mathbf{u}_t) \\\\ \n",
    "& \\approx f(\\mathbf{x}_t, \\mathbf{u}_t)\n",
    "+ \\frac{\\partial f}{\\partial \\mathbf{x}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{x}_t\n",
    "+ \\frac{\\partial f}{\\partial \\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{u}_t\n",
    "+ \\frac{1}{2} \\left(\n",
    "\\frac{\\partial^2 f}{\\partial \\mathbf{x}^2}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{x}_t^2\n",
    "+ 2 \\frac{\\partial^2 f}{\\partial \\mathbf{x}\\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{x}_t\\delta\\mathbf{u}_t\n",
    "+ \\frac{\\partial^2 f}{\\partial \\mathbf{u}^2}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{u}_t^2\n",
    "\\right)\n",
    "\\\\\n",
    "\\delta\\mathbf{x}_{t+1} &= f_x\\delta\\mathbf{x}_t + f_u\\delta\\mathbf{u}_t + \\frac{1}{2} \\left(\n",
    "f_{xx} \\delta\\mathbf{x}_t^2 + 2 f_{xu} \\delta\\mathbf{x}_t \\delta\\mathbf{u}_t + f_{uu} \\delta\\mathbf{u}_t^2\n",
    "\\right)\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which leads to a different expansion of the $Q$-function:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "Q_x &= l_x + f_x^T s_{t+1} \\\\\n",
    "Q_u &= l_u + f_u^T s_{t+1} \\\\\n",
    "Q_{xx} &= l_{xx} + f_x^T S_{t+1} f_x + S_{t+1} \\cdot f_{xx} \\\\\n",
    "Q_{uu} &= l_{uu} + B_t^T S_{t+1} B_t + S_{t+1} \\cdot f_{xu} \\\\\n",
    "Q_{ux} &= l_{ux} + B_t^T S_{t+1} A_t + S_{t+1} \\cdot f_{uu} \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The difference with iLQR is that the last term in the last 3 equations is the product of a vector with a tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The optimal control modification $\\delta\\mathbf{u}^∗$ for some state perturbation $\\delta\\mathbf{x}$, is obtained by minimizing the quadratic model:\n",
    "\n",
    "$$\n",
    "\\delta\\mathbf{u}^∗(\\delta\\mathbf{x}) = \\displaystyle\\arg\\min_{\\delta\\mathbf{u}} Q(\\delta\\mathbf{x}, \\delta\\mathbf{u}) = k + K\\delta\\mathbf{x}\n",
    "$$\n",
    "\n",
    "This is a locally-linear feedback policy with:\n",
    "\n",
    "$$\n",
    "k := -Q_{uu}^{-1}Q_u\\\\\n",
    "K := -Q_{uu}^{-1}Q_{ux}\n",
    "$$\n",
    "\n",
    "Plugging this back into the expansion of $Q$, a quadratic model of $V$ is obtained. After simplification it is:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\Delta V &= -\\frac{1}{2} k^T Q_{uu} k\\\\\n",
    "s &= Q_x - K^T Q_{uu} k\\\\\n",
    "S &= Q_{xx} - K^T Q_{uu} K\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mass-Spring-Damper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[do-mpc](https://www.do-mpc.com/en/latest/) uses [CasADi](https://web.casadi.org/python-api/) (an open-source tool for nonlinear optimization and algorithmic differentiation) for the modeling part and for the different cost functions. Here's a table of useful operators:\n",
    "\n",
    "| Operator | Description |Equation |\n",
    "| --- | --- | --- |\n",
    "| [casadi.sumsqr(x)](https://web.casadi.org/python-api/#casadi.casadi.sumsqr) | Squared-sum | $\\sum x_i^2$ |\n",
    "| [casadi.norm_2(x)](https://web.casadi.org/python-api/#casadi.casadi.norm_2) | $L_2$-norm | $\\sqrt{\\sum x_i^2}$ |\n",
    "| [casadi.norm_1(x)](https://web.casadi.org/python-api/#casadi.casadi.norm_1) | $L_1$-norm | $\\sum |x_i|$ |\n",
    "| [casadi.bilin(A, x)](https://web.casadi.org/python-api/#casadi.casadi.bilin) | Quadratic Form | $x^T A x$ |\n",
    "| [casadi.bilin(A, x, y)](https://web.casadi.org/python-api/#casadi.casadi.bilin) | Bilinear Form | $x^T A y$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Controller\n",
    "\n",
    "First, we create an instance of the MPC class is generated with the Mass-Spring-Damper prediction model defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mpc = do_mpc.controller.MPC(mass_spring_damper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We choose the finite prediction horizon `n_horizon = 20`, the time step `t_step = 0.04s` to be the same as the environment's time step. We also set the parameters of the applied discretization scheme orthogonal collocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "env = create_mass_spring_damper_environment()\n",
    "mpc_params = {\n",
    "    \"n_horizon\": 20,\n",
    "    \"t_step\": env.dt,\n",
    "    \"state_discretization\": \"collocation\",\n",
    "    \"collocation_type\": \"radau\",\n",
    "    \"collocation_deg\": 3,\n",
    "    \"collocation_ni\": 1,\n",
    "    \"store_full_solution\": True,\n",
    "    # Use MA27 linear solver in ipopt for faster calculations:\n",
    "    \"nlpsol_opts\": {\"ipopt.linear_solver\": \"mumps\"},\n",
    "}\n",
    "mpc.set_param(**mpc_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Objective\n",
    "\n",
    "The control objective is to move the mass to a desired position (`0.1`) and keep it there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xss = np.array([0.1, 0.0])\n",
    "distance_cost = 100 * casadi.norm_2(mass_spring_damper.x.cat - xss)\n",
    "terminal_cost = distance_cost\n",
    "stage_cost = distance_cost\n",
    "print(f\"{stage_cost=}\")\n",
    "print(f\"{terminal_cost=}\")\n",
    "mpc.set_objective(mterm=terminal_cost, lterm=stage_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We also restrict the input force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "force_penalty = 1e-2\n",
    "mpc.set_rterm(force=force_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Constraints\n",
    "\n",
    "We apply constraints on the force. In this case, there is only an upper and lower bounds for the force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# lower and upper bounds of the input\n",
    "u_max = 20\n",
    "mpc.bounds[\"lower\", \"_u\", \"force\"] = -u_max\n",
    "mpc.bounds[\"upper\", \"_u\", \"force\"] = u_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Setup\n",
    "\n",
    "We can now setup the controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mpc.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Simulation\n",
    "\n",
    "We set the initial state and simulate the closed-loop for 100 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "mpc.reset_history()\n",
    "mass_spring_damper_simulator.reset_history()\n",
    "x0 = np.zeros((2, 1))\n",
    "mass_spring_damper_simulator.x0 = x0\n",
    "mpc.x0 = x0\n",
    "mpc.set_initial_guess()\n",
    "for k in range(100):\n",
    "    u0 = mpc.make_step(x0)\n",
    "    x0 = mass_spring_damper_simulator.make_step(u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "animate_mass_spring_damper_simulation(mpc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Evaluation\n",
    "\n",
    "Finally, we evaluate the controller on the actual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class MPCController:\n",
    "    def __init__(self, mpc: do_mpc.controller.MPC) -> None:\n",
    "        self.mpc = mpc\n",
    "        self.mpc.reset_history()\n",
    "        self.mpc.x0 = np.zeros(2)\n",
    "        self.mpc.set_initial_guess()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return mpc.make_step(observation.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "max_steps = 100\n",
    "env = create_mass_spring_damper_environment(render_mode=render_mode, max_steps=max_steps)\n",
    "controller = MPCController(mpc)\n",
    "results = simulate_environment(env, max_steps=max_steps, controller=controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "show_video(results.frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "animate_mass_spring_damper_simulation(mpc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "- Design an MPC controller for the linearized inverted pendulum.\n",
    "- For each case, try different cost functions:\n",
    "  - $\\sum \\theta^2$\n",
    "  - $\\sum |\\theta|$\n",
    "  - $E_{\\text{kinetic}} - E_{\\text{potential}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "#### Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "mpc = do_mpc.controller.MPC(inverted_pendulum_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "mpc_params = {\n",
    "    \"n_horizon\": 50,\n",
    "    \"t_step\": env.dt,\n",
    "    \"state_discretization\": \"collocation\",\n",
    "    \"collocation_type\": \"radau\",\n",
    "    \"collocation_deg\": 3,\n",
    "    \"collocation_ni\": 1,\n",
    "    \"store_full_solution\": True,\n",
    "    # Use MA27 linear solver in ipopt for faster calculations:\n",
    "    \"nlpsol_opts\": {\"ipopt.linear_solver\": \"mumps\"},\n",
    "}\n",
    "mpc.set_param(**mpc_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "#### Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "xss = np.array([0.0, 0.0])\n",
    "distance_cost = casadi.bilin(np.diag([100, 1]), inverted_pendulum_lin.x.cat - xss)\n",
    "terminal_cost = distance_cost\n",
    "stage_cost = distance_cost\n",
    "print(f\"{stage_cost=}\")\n",
    "print(f\"{terminal_cost=}\")\n",
    "mpc.set_objective(mterm=terminal_cost, lterm=stage_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "force_penalty = 1e-4\n",
    "mpc.set_rterm(force=force_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "#### Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# lower and upper bounds of the input\n",
    "u_max = 3\n",
    "mpc.bounds[\"lower\", \"_u\", \"force\"] = -u_max\n",
    "mpc.bounds[\"upper\", \"_u\", \"force\"] = u_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "mpc.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "mpc.reset_history()\n",
    "inverted_pendulum_lin_simulator.reset_history()\n",
    "x0 = np.zeros((2, 1))\n",
    "x0[0] = 0.01\n",
    "inverted_pendulum_lin_simulator.x0 = x0\n",
    "mpc.x0 = x0\n",
    "mpc.set_initial_guess()\n",
    "for k in range(100):\n",
    "    u0 = mpc.make_step(x0)\n",
    "    x0 = inverted_pendulum_lin_simulator.make_step(u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "animate_inverted_pendulum_simulation(mpc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "class MPCController:\n",
    "    def __init__(self, mpc: do_mpc.controller.MPC) -> None:\n",
    "        self.mpc = mpc\n",
    "        self.mpc.reset_history()\n",
    "        self.mpc.x0 = np.zeros(2)\n",
    "        self.mpc.set_initial_guess()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return mpc.make_step(observation[[1, 3]].reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "max_steps = 500\n",
    "env = create_inverted_pendulum_environment(render_mode=render_mode, max_steps=max_steps)\n",
    "controller = MPCController(mpc)\n",
    "results = simulate_environment(env, max_steps=max_steps, controller=controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "show_video(results.frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "animate_inverted_pendulum_simulation(mpc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "- Design an MPC Controller for the non-linear inverted pendulum system for two different cases:\n",
    "  1. Cart at origin and upright Pendulm: Set the reference for the cart position to the origin.\n",
    "  2. Pendulum Swing-up: Set the initial angle to to $-\\pi$ i.e. start with the pendulum at the bottom.\n",
    "  3. Same as 2 but set the reference for the cart position to the origin.\n",
    "  4. Make the pendulum rotate as fast as possible.\n",
    "  \n",
    "> **Note 1** Use the following to create the environment with initial angle set to -np.pi and cutoff angle to np.inf for second > case.\n",
    "> ```python\n",
    "> env = create_inverted_pendulum_environment(cutoff_angle=np.inf, initial_angle=-np.pi)\n",
    "> ```\n",
    "\n",
    "> **Note 2**: You can access the inverted pendulum's kinetic, respectively potential, energy using\n",
    "> `inverted_pendulum.aux[\"E_kinetic\"]`, respectively `inverted_pendulum.aux[\"E_potential\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Swing-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "#### Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "mpc = do_mpc.controller.MPC(inverted_pendulum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "mpc_params = {\n",
    "    \"n_horizon\": 100,\n",
    "    \"t_step\": env.dt,\n",
    "    \"state_discretization\": \"collocation\",\n",
    "    \"collocation_type\": \"radau\",\n",
    "    \"collocation_deg\": 3,\n",
    "    \"collocation_ni\": 1,\n",
    "    \"store_full_solution\": True,\n",
    "    # Use MA27 linear solver in ipopt for faster calculations:\n",
    "    \"nlpsol_opts\": {\"ipopt.linear_solver\": \"mumps\"},\n",
    "}\n",
    "mpc.set_param(**mpc_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "#### Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "energy_cost = inverted_pendulum.aux[\"E_kinetic\"] - inverted_pendulum.aux[\"E_potential\"]\n",
    "terminal_cost = energy_cost\n",
    "stage_cost = energy_cost\n",
    "print(f\"{stage_cost=}\")\n",
    "print(f\"{terminal_cost=}\")\n",
    "mpc.set_objective(mterm=terminal_cost, lterm=stage_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "force_penalty = 0.1\n",
    "mpc.set_rterm(force=force_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "#### Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# lower and upper bounds of the position\n",
    "x_max = 1\n",
    "mpc.bounds[\"lower\", \"_x\", \"position\"] = -x_max\n",
    "mpc.bounds[\"upper\", \"_x\", \"position\"] = x_max\n",
    "# lower and upper bounds of the input\n",
    "u_max = 3\n",
    "mpc.bounds[\"lower\", \"_u\", \"force\"] = -u_max\n",
    "mpc.bounds[\"upper\", \"_u\", \"force\"] = u_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "mpc.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "mpc.reset_history()\n",
    "inverted_pendulum_simulator.reset_history()\n",
    "x0 = np.array([0.0, -0.99 * np.pi, 0.0, 0.0])\n",
    "inverted_pendulum_simulator.x0 = x0\n",
    "mpc.x0 = x0\n",
    "mpc.set_initial_guess()\n",
    "for k in range(100):\n",
    "    u0 = mpc.make_step(x0)\n",
    "    x0 = inverted_pendulum_simulator.make_step(u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "animate_full_inverted_pendulum_simulation(mpc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "class MPCController:\n",
    "    def __init__(self, mpc: do_mpc.controller.MPC) -> None:\n",
    "        self.mpc = mpc\n",
    "        self.mpc.reset_history()\n",
    "        self.mpc.x0 = np.array([0.0, -0.99 * np.pi, 0.0, 0.0])\n",
    "        self.mpc.set_initial_guess()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return mpc.make_step(observation.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "max_steps = 500\n",
    "env = create_inverted_pendulum_environment(\n",
    "    render_mode=render_mode, max_steps=max_steps, cutoff_angle=np.inf, initial_angle=-np.pi\n",
    ")\n",
    "controller = MPCController(mpc)\n",
    "results = simulate_environment(env, max_steps=max_steps, controller=controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "show_video(results.frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "animate_full_inverted_pendulum_simulation(mpc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPC and AlphaZero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "AlphaZero is a computer program developed by artificial intelligence research company DeepMind to master the games of chess, shogi and go.\n",
    "\n",
    "It is built from three core pieces:\n",
    "\n",
    "- Value Function (Neural Network) to estimate the optimal cost-to-go for any given state.\n",
    "- Policy (Neural Network) to determine the action to take at a given state.\n",
    "- Monte Carlo Tree Search to simulate and search for the best plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "<figure style=\"float: left; width: 60%;\">\n",
    "    <img src=\"_static/images/30_alphazero_online_play.png\" width=\"100%\"/>\n",
    "</figure>\n",
    "<div style=\"float: right; width: 30%;\">\n",
    "Illustration of an on-line player such as the one used in AlphaGo,\n",
    "AlphaZero, and Tesauro’s backgammon program. At a given position,\n",
    "it generates a lookahead tree of multiple moves up to some depth, then runs\n",
    "the off-line obtained player for some more moves, and evaluates the effect of the\n",
    "remaining moves by using the position evaluator of the off-line player.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In AlphaZero, the policy and value networks are trained off-line and an approximate version of the fundamental DP algorithm of policy iteration. A separate on-line player is used to select moves, based on multistep lookahead minimization and a terminal position evaluator that was trained using experience with the off-line player.\n",
    "\n",
    "This approach performs better than using the off-line policy directly because of the long lookahead minimization, which corrects for the inevitable imperfections of the neural network-trained off-line\n",
    "player, and position evaluator/terminal cost approximation.\n",
    "\n",
    "In model predictive control (MPC), there is no off-line training and we use the system's model for the on-line rollout. The control interval is equivalent to the number of steps in lookahead minimization, while the prediction interval is equivalent to the total number of steps in lookahead minimization and truncated rollout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monte Carlo Tree Search\n",
    "\n",
    "Monte Carlo Tree Search (MCTS) is a heuristic search algorithm which uses stochastic simulations for decision processes, most notably those employed in software that plays board games. In that context MCTS is used to solve the game tree.\n",
    "\n",
    "MCTS was combined with neural networks in 2016 and has been used in multiple board games like Chess, Shogi, Checkers, Backgammon, Contract Bridge, Go, Scrabble, and Clobber as well as in turn-based-strategy video games (such as Total War: Rome II's implementation in the high level campaign AI). \n",
    "\n",
    "The method especially took off due its effectiveness in computer Go and is still being used in DeepMind’s AlphaGoZero the most advanced Go AI to date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "MCTS consists of 4 steps that are repeated until some condition is met:\n",
    "\n",
    "1. **Selection**: The selection phase traverses the tree level by level, each time\n",
    "   selecting a node based on stored statistics like \"number of visits\"\n",
    "   or \"total reward\". The rule by which the algorithm selects is called the tree policy.\n",
    "   Selection stops when a node is reached that is not fully explored yet, i.e.\n",
    "   not all possible moves have been expanded to new nodes yet.\n",
    "2. **Expansion**: The expansion step consists of adding one or multiple new \n",
    "   child nodes to the final selected node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "3. **Rollout**: A rollout is initiated from each of these added nodes.\n",
    "   Depending on the mean depth of the tree, rollout is done until the end of the game or\n",
    "   as deep as possible before performing an evaluation. When dealing with\n",
    "   terminal states in games the evaluation is done based on the win condition\n",
    "   and usually yields 0 (loss), 0.5 (draw) or 1 (win).\n",
    "   In the original algorithm the rollout is performed at random, but in general\n",
    "   the so-called default policy can be enhanced by heuristics. For example,\n",
    "   in the case of AlphaGoZero the rollout step was completely replaced by a\n",
    "   neural network evaluation function.\n",
    "4. **Backup**: The outcome of the rollout step is backed up to the nodes involved \n",
    "   in the selection phase by updating their respective statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<figure>\n",
    "    <img src=\"_static/images/30_monte_carlo_tree_search.svg\" width=\"100%\"/>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "- Planning plays an important role in control, decision making and reinforcement learning.\n",
    "- Optimal Control is the branch of Control Theory concerned with optimizing a cost function through the use of open-loop planning.\n",
    "- The Linear Quadratic Regulator (LQR) is an optimal feedback control law that optimizes a quadratic cost function for LTI systems.\n",
    "- Model Predictive Control (MPC) is a control scheme that uses planning in a receding horizon to determine the best action to take at each time step.\n",
    "- MPC uses the system's model for the rollout and can approached in many different ways such as iLQR and DDP.\n",
    "- AlphaZero uses off-line learning and on-line planning to tackle different types of games. Unlike MPC it uses neural networks to determine the next best action and to approximate the cost-to-go. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell",
     "remove-cell-nbconv"
    ]
   },
   "source": [
    "<img src=\"_static/images/aai-institute-cover.svg\" alt=\"Snow\" style=\"width:100%;\">\n",
    "<div class=\"md-slide title\">Thank you for the attention!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "- [<b id=\"slotine_applied_1991\">[Slotine 1991]</b>](#slotine_applied_1991-back) [Applied nonlinear control.](https://www.academia.edu/download/33582713/Applied_Nonlinear_Control_Slotine.pdf) Slotine, Jean-Jacques E., and Weiping Li. Vol. 199, no. 1. Englewood Cliffs, NJ: Prentice hall. 1991.\n",
    "\n",
    "- [<b id=\"grune_nonlinear_2017\">[Lars Nonlinear 2017]</b>](#grune_nonlinear_2017-back) [Nonlinear model predictive control.](https://link.springer.com/chapter/10.1007/978-3-319-46024-6_3) Grüne, Lars, Jürgen Pannek, Lars Grüne, and Jürgen Pannek. Springer International Publishing, 2017.\n",
    "\n",
    "- [<b id=\"biral_notes_2016\">[Biral Notes 2016]</b>](#biral_notes_2016-back) [Notes on numerical methods for solving optimal control problems.](https://www.jstage.jst.go.jp/article/ieejjia/5/2/5_154/_article/-char/ja/) Biral, Francesco, Enrico Bertolazzi, and Paolo Bosetti. IEEJ Journal of Industry Applications 5, no. 2 (2016): 154-166.\n",
    "\n",
    "- [<b id=\"bertsekas_lessons_2022\">[Bertsektas, Dimitri P, 2022]</b>](#bertsekas_lessons_2022-back) [Lessons from AlphaZero for Optimal, Model Predictive, and Adaptive Control](http://web.mit.edu/dimitrib/www/LessonsfromAlphazero.pdf) - Dimitri P. Bertsektas. 2022.\n",
    "\n",
    "- [<b id=\"spencer_optimal_2023\">[Spencer et al. 2023]</b>](#spencer_optimal_2023-back) [AA 203: Optimal and Learning-Based Control.](https://stanfordasl.github.io/aa203/sp2223/) Optimal control solution techniques for systems with known and unknown dynamics. 2023.\n",
    "\n",
    "- [<b id=\"tedrake_underactuated_2023\">[Russ Tedrake, 2023]</b>](#tedrake_underactuated_2023-back) [Underactuated Robotics: Algorithms for Walking, Running, Swimming, Flying, and Manipulation (Course Notes for MIT 6.832)](http://underactuated.mit.edu/index.html) Russ Tedrake. Downloaded on 24.10.2023."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "rise": {
   "footer": "<img src='_static/images/aai-logo.png' alt='logo' height='50em'>",
   "header": "<img src='_static/images/transferlab-logo.svg' alt='logo' height='20em' />",
   "theme": "white"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "148px",
    "width": "256px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "563.2px",
    "left": "125px",
    "top": "116.469px",
    "width": "315.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
