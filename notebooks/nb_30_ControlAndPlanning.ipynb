{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input",
     "remove-output",
     "remove-input-nbconv",
     "remove-output-nbconv"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext training_rl\n",
    "%set_random_seed 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%presentation_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_latex_macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import warnings\n",
    "\n",
    "import casadi\n",
    "import control as ct\n",
    "import do_mpc\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotx\n",
    "import mediapy as media\n",
    "import mujoco\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML\n",
    "from ipywidgets import interact, widgets\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from numpy.typing import NDArray\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "from training_rl.environment import (\n",
    "    create_inverted_pendulum_environment,\n",
    "    create_mass_spring_damper_environment,\n",
    ")\n",
    "from training_rl.control import (\n",
    "    create_shortest_path_graph,\n",
    "    plot_shortest_path_graph,\n",
    "    plot_all_paths_graph,\n",
    ")\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "sns.set_theme()\n",
    "plt.rcParams[\"figure.figsize\"] = [9, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"_static/images/aai-institute-cover.svg\" alt=\"presentation first slide\" style=\"width:100%;\">\n",
    "<div class=\"md-slide title\">Control and Planning</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In previous sections, we have designed feedback controllers for various systems with the goal of regulating the system output to a desired setpoint. Specifically, we utilized Fullstate Feedback and PID controllers. While these simple controllers can effectively regulate many systems, they have limitations that prevent high performance control for more complex systems.\n",
    "\n",
    "First, these controllers have a fixed, static gain that does not change over time. This limits their ability to adapt to changing system dynamics or disturbances. Second, after developing a mathematical model of the system dynamics, we did not actually utilize the model in the controller design. A model-based approach could allow us to leverage our understanding of the system to improve control performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One ubiquitous challenge in control system design is the presence of control input constraints. Actuators in physical systems inherently have limits on their amplitude and rate of change. For example, a motor has maximum torque and acceleration limits. If control input constraints are ignored in the controller design, the resulting control inputs may saturate the actuators, degrading closed-loop performance.\n",
    "\n",
    "There are two main strategies to address control input constraints:\n",
    "\n",
    "- Reduce the performance requirements to levels achievable with a linear controller without violating the constraints.\n",
    "- Directly account for the constraints by modifying the control design and online optimization of the control input.   For example, model predictive control utilizes the system model to predict future behavior and optimize the control input while satisfying constraints.\n",
    "\n",
    "In subsequent sections, we will explore model-based and optimization-based control techniques to overcome the limitations of basic controllers. Properly managing control input constraints is crucial to achieving high performance in real control systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mass-Spring-Damper Model\n",
    "\n",
    "\n",
    "<div>\n",
    "<figure style=\"float: left; width: 50%;\">\n",
    "    <img src=\"_static/images/20_mass_spring_damper.svg\" width=\"50%\"/>\n",
    "    <figcaption>\n",
    "        Classic model used for deriving the equations of a mass spring damper model <a href=\"#wiki_mass_spring_damper\"><b id=\"wiki_mass_spring_damper-back\">[Wiki Mass-Spring-Damper, 2023]</b></a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "<div style=\"float: left; width: 40%;\">\n",
    "    \n",
    "- $z(t)$: Distance along the vertical axis from some reference point.\n",
    "- $m$: Mass of the object.\n",
    "- $\\lambda$: Coefficient of elasticity.\n",
    "- $l$: Length of spring.\n",
    "- $k = \\frac{\\lambda}{l}$\n",
    "- $c$: Damping coefficient.\n",
    "- $f(t)$: Force applied on the object.\n",
    "- $g$: Gravity.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The system has linear state-space model with matrices:\n",
    "\n",
    "$$\n",
    "A\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "-\\frac{k}{m} & -\\frac{c}{m}\\\\\n",
    "\\end{bmatrix};\n",
    "B\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\frac{1}{m}\\\\\n",
    "\\end{bmatrix};\n",
    "C = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "\\end{bmatrix};\n",
    "D = \\begin{bmatrix}\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "m = 0.51\n",
    "c = 1.52\n",
    "k = 50.15\n",
    "# Dynamics matrix\n",
    "A = np.array(\n",
    "    [\n",
    "        [0, 1],\n",
    "        [-k / m, -c / m],\n",
    "    ]\n",
    ")\n",
    "# Input matrix\n",
    "B = np.array([[0, 1 / m]]).transpose()\n",
    "# Output matrices\n",
    "C = np.array(\n",
    "    [\n",
    "        [1, 0],\n",
    "    ]\n",
    ")\n",
    "D = np.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mass_spring_damper = do_mpc.model.LinearModel(\"continuous\")\n",
    "mass_spring_damper.set_variable(var_type=\"_x\", var_name=\"position\")\n",
    "mass_spring_damper.set_variable(var_type=\"_x\", var_name=\"velocity\")\n",
    "mass_spring_damper.set_variable(var_type=\"_u\", var_name=\"force\")\n",
    "mass_spring_damper.setup(A, B, C, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_mass_spring_damper_environment()\n",
    "mass_spring_damper = mass_spring_damper.discretize(env.dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Inverted Pendulum\n",
    "\n",
    "<div>\n",
    "<figure style=\"float: left; width: 40%;\">\n",
    "    <img src=\"_static/images/20_inverted_pendulum.svg\" width=\"50%\"/>\n",
    "    <figcaption>\n",
    "        Inverted pendulum model <a href=\"#goodwin_control_2000\"><b id=\"goodwin_control_2000-back\">[Goodwin et al., 2000]</b></a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "<div style=\"float: left; width: 50%\">\n",
    "    \n",
    "- $y(t)$: distance along the horizontal axis from some reference point.\n",
    "- $\\theta(t)$: angle of the pendulum.\n",
    "- $M$: mass of the cart.\n",
    "- $m$: mass of the pendulum (assumed to be concentrated at the tip).\n",
    "- $l$: length of the pendulum.\n",
    "- $f(t)$: force applied on the cart.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The system has the following full non-linear state space model:\n",
    "\n",
    "$$\n",
    "\\dot{X}(t) = \\begin{bmatrix}\n",
    "\\dot{x_1}(t) \\\\ \\dot{x_2}(t) \\\\ \\dot{x_3}(t) \\\\ \\dot{x_4}(t)\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "x_2(t) \\\\\n",
    "x_4(t) \\\\\n",
    "\\frac{1}{\\lambda_m + \\sin^2 x_2(t)} \\left[\n",
    "\\frac{u(t)}{m} + x_4(t)^2 l \\sin x_2(t) - g \\cos x_2(t) \\sin x_2(t)\n",
    "\\right] \\\\\n",
    "\\frac{1}{l\\lambda_m + \\sin^2 x_2(t)} \\left[\n",
    "-\\frac{u(t)}{m}\\cos x_2(t) + x_4(t)^2 l \\sin x_2(t) \\cos x_2(t) + (1 - \\lambda_m) \\sin x_2(t)\n",
    "\\right] \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And the following partial (pendulum angle only) non-linear state space model:\n",
    "\n",
    "$$\n",
    "\\dot{X}(t) = \\begin{bmatrix}\n",
    "\\dot{x_1}(t) \\\\ \\dot{x_2}(t)\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "x_2(t) \\\\\n",
    "\\frac{1}{l\\lambda_m + \\sin^2 x_1(t)} \\left[\n",
    "-\\frac{u(t)}{m}\\cos x_1(t) + x_2(t)^2 l \\sin x_1(t) \\cos x_1(t) + (1 - \\lambda_m) \\sin x_1(t)\n",
    "\\right] \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And the following linearized (around $\\theta = 0$ and $\\dot{\\theta} = 0$) state space model:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "\\frac{(M + m)g}{Ml} & 0\\\\\n",
    "\\end{bmatrix};\n",
    "B = \\begin{bmatrix}\n",
    "0 \\\\ -\\frac{1}{Ml}\n",
    "\\end{bmatrix};\n",
    "C = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "\\end{bmatrix};\n",
    "D = \\begin{bmatrix}\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "g = 9.81\n",
    "l = env.model.geom_pos[2, 2]\n",
    "m = env.model.body_mass[2]\n",
    "M = env.model.body_mass[1]\n",
    "lambda_m = M / m\n",
    "\n",
    "# Dynamics matrix\n",
    "A = np.array(\n",
    "    [\n",
    "        [0, 1],\n",
    "        [(1 + lambda_m) * g / (lambda_m * l), 0],\n",
    "    ]\n",
    ")\n",
    "# Input matrix\n",
    "B = np.array([[0, -1 / (M * l)]]).transpose()\n",
    "# Output matrices\n",
    "C = np.array(\n",
    "    [\n",
    "        [1, 0],\n",
    "    ]\n",
    ")\n",
    "D = np.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum_lin = do_mpc.model.LinearModel(\"continuous\")\n",
    "theta = inverted_pendulum_lin.set_variable(var_type=\"_x\", var_name=\"theta\")\n",
    "dtheta = inverted_pendulum_lin.set_variable(var_type=\"_x\", var_name=\"dtheta\")\n",
    "inverted_pendulum_lin.set_variable(var_type=\"_u\", var_name=\"force\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We also define the pendulum's kinetic and potential energies:\n",
    "\n",
    "$E_{\\text{kinetic}} = \\frac{1}{2} m \\left( (l x_2 \\cos(x_1))^{2} + (l x_2 \\sin(x_1))^{2} \\right)$\n",
    "    \n",
    "$E_{\\text{potential}} = m g  l \\cos(x_1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Energies\n",
    "E_kin = 0.5 * m * ((l * dtheta * casadi.cos(theta)) ** 2 + (l * dtheta * casadi.sin(theta)) ** 2)\n",
    "E_pot = m * g * l * casadi.cos(theta)\n",
    "inverted_pendulum_lin.set_expression(\"E_kinetic\", E_kin)\n",
    "inverted_pendulum_lin.set_expression(\"E_potential\", E_pot);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum_lin.setup(A, B, C, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "inverted_pendulum_lin = inverted_pendulum_lin.discretize(env.dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We also define the full non-linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum = do_mpc.model.Model(\"continuous\")\n",
    "\n",
    "position = inverted_pendulum.set_variable(var_type=\"_x\", var_name=\"position\")\n",
    "theta = inverted_pendulum.set_variable(var_type=\"_x\", var_name=\"theta\")\n",
    "velocity = inverted_pendulum.set_variable(var_type=\"_x\", var_name=\"velocity\")\n",
    "dtheta = inverted_pendulum.set_variable(var_type=\"_x\", var_name=\"dtheta\")\n",
    "u = inverted_pendulum.set_variable(var_type=\"_u\", var_name=\"force\")\n",
    "\n",
    "denominator = lambda_m + casadi.sin(theta) ** 2\n",
    "nominator = (\n",
    "    u / m * casadi.cos(theta)\n",
    "    + dtheta**2 * l * casadi.sin(theta)\n",
    "    - g * casadi.sin(theta) * casadi.cos(theta)\n",
    ")\n",
    "\n",
    "inverted_pendulum.set_rhs(\"position\", velocity)\n",
    "inverted_pendulum.set_rhs(\"velocity\", nominator / denominator)\n",
    "\n",
    "denominator = l * lambda_m + casadi.sin(theta) ** 2\n",
    "nominator = (\n",
    "    -u / m * casadi.cos(theta)\n",
    "    + dtheta**2 * l * casadi.sin(theta) * casadi.cos(theta)\n",
    "    + (1 - lambda_m) * casadi.sin(theta)\n",
    ")\n",
    "\n",
    "inverted_pendulum.set_rhs(\"theta\", dtheta)\n",
    "inverted_pendulum.set_rhs(\"dtheta\", nominator / denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And kinetic and potential energies:\n",
    "\n",
    "$E_{\\text{kinetic}} = E_{\\text{kinetic, cart}} + E_{\\text{kinetic, pendulum}}$\n",
    "    \n",
    "$E_{\\text{kinetic, cart}} = \\frac{1}{2} M x_3^{2}$\n",
    "    \n",
    "$E_{\\text{kinetic, pendulum}} = \\frac{1}{2} m \\left( (x_3 + l x_4 \\cos(x_2))^{2} + (l x_4 \\sin(x_2))^{2} \\right)$\n",
    "    \n",
    "$E_{\\text{potential}} = m g  l \\cos(x_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Energies\n",
    "E_kin = 0.5 * M * velocity**2 + 0.5 * m * (\n",
    "    (velocity + l * dtheta * casadi.cos(theta)) ** 2 + (l * dtheta * casadi.sin(theta)) ** 2\n",
    ")\n",
    "E_pot = m * g * l * casadi.cos(theta)\n",
    "inverted_pendulum.set_expression(\"E_kinetic\", E_kin)\n",
    "inverted_pendulum.set_expression(\"E_potential\", E_pot);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimal Control\n",
    "\n",
    "Optimal control theory is a branch of control theory that deals with finding a control for a dynamical system over a period of time such that an objective function is optimized. The fundamental idea in optimal control is to formulate the goal of control as the long-term optimization of a scalar cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The optimal control problem is to find a control $u^* \\in \\mathbf{U}$ which causes the system $\\dot{x}(t) = f(x(t), u(t))$ to follow a trajectory $x^* \\in \\mathbf{X}$ that minimizes the cost (performance measure):\n",
    "\n",
    "\n",
    "### Continuous-time\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\displaystyle  \\min_{x, u} & J(x, u) & \\text{(cost)}\\\\\n",
    "\\text{subject to} & \\dot{x}(t) = f(x(t), u(t)) & \\text{(dynamical feasibility)}\\\\\n",
    "& x(t_0) = x_0, x(T) \\in \\mathbf{X_T} & \\text{(boundary conditions)}\\\\\n",
    "& x(t) \\in \\mathbf{X} , \\forall t \\in [0, T] & \\text{(state constraints)}\\\\\n",
    "& u(t) \\in \\mathbf{U}, \\forall t \\in [0, T] & \\text{(input constraints)}\\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Discrete-time\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\displaystyle  \\min_{x, u} & J(x, u) & \\text{(cost)}\\\\\n",
    "\\text{subject to} & x_{t+1} = f(x_t, u_t) & \\text{(dynamical feasibility)}\\\\\n",
    "& x_{t_0} = x_0, x_N \\in \\mathbf{X_N} & \\text{(boundary conditions)}\\\\\n",
    "& x_t \\in \\mathbf{X} , \\forall t \\in \\{0, 1, \\dots , N - 1\\} & \\text{(state constraints)}\\\\\n",
    "& u_t \\in \\mathbf{U}, \\forall t \\in \\{0, 1, \\dots , N - 1\\} & \\text{(input constraints)}\\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Finite Horizon \n",
    "\n",
    "- Continuous-time:\n",
    "\n",
    "$$\n",
    "J_{T}(x_0, u) = l_f(x(T)) + \\int \\limits_{0}^{T} l(x(t), u(t)) dt\n",
    "$$\n",
    "\n",
    "- Discrete-time:\n",
    "\n",
    "$$\n",
    "J_N(x_0, u) = l_f(x_N) + \\sum \\limits_{k = 0}^{N-1} l(x_k, u_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Infinite Horizon\n",
    "\n",
    "- Continuous-time:\n",
    "\n",
    "$$\n",
    "J(x_0, u) = \\int \\limits_{0}^{\\infty} l(x(t), u(t)) dt\n",
    "$$\n",
    "\n",
    "- Discrete-time:\n",
    "\n",
    "$$\n",
    "J(x_0, u) = \\sum \\limits_{k = 0}^{\\infty} l(x_k, u_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This approach is powerful for a number of reasons. First and foremost, it is very general - allowing us to specify the goal of control equally well for fully- or under-actuated, linear or nonlinear, deterministic or stochastic, and continuous or discrete systems. Second, it permits concise descriptions of potentially very complex desired behaviours, specifying the goal of control as a scalar objective (plus a list of constraints)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Choosing the cost function\n",
    "\n",
    "Choosing a cost function means translating the system's desired physical state into a mathematical formulation.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Minimum-time problems: $J = t_f - t_0$\n",
    "- Terminal control problems: $J = || x(t_f) - r(t_f) ||^2$\n",
    "- Minimum control-effort problems: $J = \\sum \\limits_{k = t_0}^{t_f} |u(t_k)|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Questions\n",
    "\n",
    "- What are possible cost functions for the 2 systems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dynamic Programming\n",
    "\n",
    "Dynamic programming (DP) is a method that in general solves optimization problems that involve making a sequence of decisions by determining, for each decision, subproblems that can be solved in like fashion, such that an optimal\n",
    "solution of the original problem can be found from optimal solutions of sub-\n",
    "problems. This method is based on Bellmanâ€™s Principle of Optimality, which\n",
    "he phrased as follows:\n",
    "\n",
    "> An optimal policy has the property that whatever the initial state and\n",
    "initial decision are, the remaining decisions must constitute an optimal\n",
    "policy with regard to the state resulting from the first decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dynamic Programming is a very general solution method for problems which have two properties:\n",
    "\n",
    "- Optimal substructure (Principle of optimality applies)\n",
    "  - Optimal solution can be decomposed into subproblems, e.g., shortest path\n",
    "- Overlapping subproblems\n",
    "  - Subproblems recur many times\n",
    "  - Solutions can be cached and reused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dynamic programming is used across a wide variety of domains, e.g.\n",
    "\n",
    "- Scheduling algorithms\n",
    "- Graph algorithms (e.g., shortest path algorithms)\n",
    "- Graphical models in ML (e.g., Viterbi algorithm)\n",
    "- Bioinformatics (e.g., Sequence alignment, Protein folding) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We define the value functions as (for the sake of simplicity we will focus on the discrete-time case):\n",
    "\n",
    "$$\n",
    "V_N(x_0) := \\min_{u \\in \\mathbf{U}} J_N(x_0, u)\n",
    "$$\n",
    "\n",
    "An admissible control sequence $u^*$ is called optimal, if\n",
    "\n",
    "$$\n",
    "V_N(x_0) = J_N(x_0, u^*)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For any feasible $x_0 \\in \\mathbf{X}$ the optimal value function satisfies\n",
    "\n",
    "$$\n",
    "V_N(x_0) = \\displaystyle \\min_{u \\in \\mathbf{U} \\\\ \\displaystyle f(x_0, u) \\in \\mathbf{X}} l(x_0, u) + V_{N-1}(f(x_0, u))\n",
    "$$\n",
    "\n",
    "Moreover, if $u^*$ is an optimal control, then\n",
    "\n",
    "$$\n",
    "V_N(x_0) = l(x_0, u^*(0)) + V_{N-1}(f(x_0, u^*(0)))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  DP Algorithm\n",
    "\n",
    "For every initial state $x_0$, the optimal cost is equal to $V_N(x_0)$, given by the last step of the following algorithm, which proceeds backward in time from stage $N-1$ to stage $0$:\n",
    "\n",
    "$$\n",
    "V_N(x_N) = l(x_N)\\\\\n",
    "V_k = \\displaystyle \\min_{u \\in \\mathbf{U}} \\left\\{ l(x_k, u_k) + V_{k+1}(f(x_k, u_k)) \\right\\}\n",
    "$$\n",
    "\n",
    "The optimal cost is then equal to:\n",
    "\n",
    "$$\n",
    "J^*(x_0) = V_0(x_0)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "G = create_shortest_path_graph()\n",
    "plot_shortest_path_graph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We wish to travel from node A to node G at minimum cost. If the cost represents time then we want to find the shortest path from A to G.\n",
    "\n",
    "- Arrows (edges) indicate the possible movements.\n",
    "- Numbers on edges indicate the cost of moving along an edge.\n",
    "\n",
    "Use Dynamic Programming to solve this problem.\n",
    "\n",
    "> **Hint** Determine all possible paths first and then compute the cost-to-go at each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_all_paths_graph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Each node in this new graph represents a state. We will start from the tail (the last states) and compute recursively the cost for each state transition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We start by determining the cost-to-go for all positions.\n",
    "\n",
    "Let $l(n_1, n_2)$ the cost of going from node $n_1$ to $n_2$ and $V(n)$ be the cost-to-go from node $n$.\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V(\\text{ABDF}) &= l(\\text{ABDF}, \\text{ABDFG}) &= 1\\\\\n",
    "V(\\text{ABE}) &= l(\\text{ABE}, \\text{ABEG}) &= 4\\\\\n",
    "V(\\text{ACF}) &= l(\\text{ACF}, \\text{ACFG}) &= 1\\\\\n",
    "V(\\text{ADF}) &= l(\\text{ADF}, \\text{ADFG}) &= 1\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V(\\text{ABD}) &= \\min \\left[ l(\\text{ABD}, \\text{ABDG}), l(\\text{ABD}, \\text{ABDF}) + V(\\text{ABDF}) \\right]\n",
    "&= \\min \\left[ 8, 5 + 1 \\right] &= 6\n",
    "\\\\\n",
    "V(\\text{AB}) &= \\min \\left[ l(\\text{AB}, \\text{ABD}) + V(\\text{ABD}), l(\\text{AB}, \\text{ABE}) + V(\\text{ABE}) \\right]\n",
    "&= \\min \\left[ 9 + 5, 6 + 4 \\right] &= 10\n",
    "\\\\\n",
    "V(\\text{AC}) &= l(\\text{AC}, \\text{ACF}) + V(\\text{ACF}) &= 2 + 1 &= 3\n",
    "\\\\\n",
    "V(\\text{AD}) &= \\min \\left[ l(\\text{AD}, \\text{ADF}) + V(\\text{ADF}), l(\\text{AD}, \\text{ADG})) \\right]\n",
    "&= \\min \\left[ 5 + 1, 8 \\right] &= 6\n",
    "\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V(\\text{A}) &= \\min \\left[\n",
    "l(\\text{A}, \\text{AB}) + V(\\text{AB}), l(\\text{A}, \\text{AC}) + V(\\text{AC}), l(\\text{A}, \\text{AD}) + V(\\text{AD})\n",
    "\\right]\n",
    "&= \\min \\left[ 1 + 10, 5 + 3, 3 + 6 \\right] &= 8\n",
    "\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The shortest-path is aCFG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_all_paths_graph(G, show_solution=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Quadratic Regulator\n",
    "\n",
    "While solving the optimal control problem (OCP) is very hard in general, there are a few very important special cases where the solutions are very accessible. Most of these involve variants on the case of linear dynamics and quadratic cost. The simplest case, called the linear quadratic regulator (LQR), is formulated as stabilizing a time-invariant linear system to the origin can be solved analytically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a discrete-time linear system described by:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t+1} = A \\mathbf{x}_t + B \\mathbf{u}_t\n",
    "$$\n",
    "\n",
    "where $x\\in \\mathbb {R} ^{n}$ (that is, $x$ is an $n$-dimensional real-valued vector) is the state of the system and $u\\in \\mathbb {R} ^{m}$ is the control input. Given a quadratic cost function for the system, defined as:\n",
    "\n",
    "### Finite-Horizon\n",
    "\n",
    "$$\n",
    "J_0(\\mathbf{x}_0, \\mathbf{u}) = \\frac{1}{2} \\mathbf{x}_N^T Q \\mathbf{x}_N + \\frac{1}{2} \\sum \\limits _{k = 0}^{N - 1}  \\mathbf{x}_k^{T}Q \\mathbf{x}_k + \\mathbf{u}_k^{T} R \\mathbf{u}_k\n",
    "$$\n",
    "\n",
    "With $Q = Q^T \\succeq 0$, $R = R^T \\succeq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Infinite-Horizon\n",
    "\n",
    "$$\n",
    "J(\\mathbf{x}_0, \\mathbf{u}) = \\frac{1}{2} \\sum \\limits _{k = 0}^{\\infty} \\mathbf{x}_k^{T}Q \\mathbf{x}_k + \\mathbf{u}_k^{T} R \\mathbf{u}_k\n",
    "$$\n",
    "\n",
    "With $Q = Q^T \\succeq 0$, $R = R^T \\succeq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's solve this for the finite-horizon case using dynamic programming. We start by setting:\n",
    "\n",
    "$$\n",
    "V_N(\\mathbf{x}_N) = J_N(\\mathbf{x}_N) = \\frac{1}{2} \\mathbf{x}_{N}^T Q \\mathbf{x}_{N} = \\frac{1}{2} \\mathbf{x}_{N}^T P \\mathbf{x}_{N}\n",
    "$$\n",
    "\n",
    "And then proceed backward in time:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V_{N-1}(\\mathbf{x}_{N-1}) &=& \\displaystyle \\min_{\\mathbf{u}_{N-1}} J_{N-1}(\\mathbf{x}_{N-1}, \\mathbf{u}_{N-1})\\\\\n",
    "&=& \\displaystyle \\min_{\\mathbf{u}_{N-1}} \\frac{1}{2} \\left(\n",
    "\\mathbf{x}_{N-1}^{T} Q \\mathbf{x}_{N-1} + \\mathbf{u}_{N-1}^{T} R \\mathbf{u}_{N-1} + \\mathbf{x}_{N}^T P \\mathbf{x}_{N}\n",
    "\\right) \\\\\n",
    "&=& \\displaystyle \\min_{\\mathbf{u}_{N-1}} \\frac{1}{2} \\left(\n",
    "\\mathbf{x}_{N-1}^{T} Q \\mathbf{x}_{N-1} + \\mathbf{u}_{N-1}^{T} R \\mathbf{u}_{N-1} + (A\\mathbf{x}_{N-1} + B\\mathbf{u}_{N-1})^T P (A\\mathbf{x}_{N-1} + B\\mathbf{u}_{N-1})\n",
    "\\right)\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Taking the gradient with respect to $\\mathbf{u}_{N-1}$:\n",
    "\n",
    "$$\n",
    "\\displaystyle \\nabla_{\\mathbf{u}_{N-1}} J_{N-1}(\\mathbf{x}_{N-1}, \\mathbf{u}_{N-1}) = \n",
    "R \\mathbf{u}_{N-1} + B^T P (A \\mathbf{x}_{N-1} + B \\mathbf{u}_{N - 1}) = 0\n",
    "$$\n",
    "\n",
    "Gives us the following optimal feedback control at step $N - 1$:\n",
    "\n",
    "$$\n",
    "\\mathbf{u}^*_{N-1} = -(R + B^T P B)^{-1} B^T P B \\mathbf{x}_{N-1} = - K \\mathbf{x}_{N-1}\n",
    "$$\n",
    "\n",
    "With $K = (R + B^T P B)^{-1} B^T P B$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The optimal cost-to-go is then:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V_{N-1}(\\mathbf{x}_{N-1}) &= J_{N-1}(\\mathbf{x}_{N-1}, \\mathbf{u}^*_{N-1}) \\\\\n",
    "&= \\frac{1}{2}  \\left(\n",
    "\\mathbf{x}_{N-1}^{T} Q \\mathbf{x}_{N-1} + \\mathbf{u}_{N-1}^{*T} R \\mathbf{u}^{*}_{N-1} + \\mathbf{x}_{N}^T P \\mathbf{x}_{N}\n",
    "\\right)\\\\\n",
    "&= \\frac{1}{2}  \\left(\n",
    "\\mathbf{x}_{N-1}^{T} Q \\mathbf{x}_{N-1} + \\mathbf{u}_{N-1}^{*T} R \\mathbf{u}^{*}_{N-1} + (A\\mathbf{x}_{N-1} + B\\mathbf{u}_{N-1})^T P (A\\mathbf{x}_{N-1} + B\\mathbf{u}_{N-1})\n",
    "\\right)\\\\\n",
    "&= \\frac{1}{2}  \\left(\n",
    "\\mathbf{x}_{N-1}^{T} Q \\mathbf{x}_{N-1} + \\mathbf{x}_{N-1}^{T} K^T R K \\mathbf{x}_{N-1} + \\mathbf{x}_{N-1}^T(A - BK)^T P (A - BK)\\mathbf{x}_{N-1}\n",
    "\\right)\\\\\n",
    "&= \\frac{1}{2}  \n",
    "\\mathbf{x}_{N-1}^{T} \\left(\n",
    "Q + A^{T}PA-(A^{T}PB)(R+B^{T}PB)^{-1}(B^{T}PA)\n",
    "\\right) \\mathbf{x}_{N-1}\n",
    "\\\\\n",
    "&:= \\frac{1}{2} \\mathbf{x}_{N-1}^T P \\mathbf{x}_{N-1}\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The last step is needed to ensure that the derivation works recursively for all steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "and $P$ is found by solving the discrete time algebraic Riccati equation (DARE):\n",
    "\n",
    "$$\n",
    "Q + A^{T}PA-(A^{T}PB)(R+B^{T}PB)^{-1}(B^{T}PA) = P.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mass-Spring-Damper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the controller\n",
    "lqr = do_mpc.controller.LQR(mass_spring_damper)\n",
    "\n",
    "# Initialize the parameters\n",
    "env = create_mass_spring_damper_environment()\n",
    "lqr.settings.t_step = env.dt\n",
    "lqr.settings.n_horizon = None  # infinite horizon\n",
    "\n",
    "# Setting the objective\n",
    "Q = np.diag([100, 0])\n",
    "R = np.diag([0])\n",
    "lqr.set_objective(Q=Q, R=R)\n",
    "\n",
    "# lqr setup\n",
    "lqr.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define set point\n",
    "xss = np.array([0.1, 0.0]).reshape(-1, 1)\n",
    "lqr.set_setpoint(xss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_mass_spring_damper_environment(max_steps=100)\n",
    "initial_observation, _ = env.reset()\n",
    "\n",
    "observation = initial_observation.copy()\n",
    "observations = [observation]\n",
    "actions = []\n",
    "\n",
    "for _ in range(100):\n",
    "    action = lqr.make_step(observation.reshape(-1, 1)).ravel()\n",
    "    actions.append(action)\n",
    "    observation, _, terminated, truncated, _ = env.step(action)\n",
    "    observations.append(observation)\n",
    "    if terminated or truncated:\n",
    "        frames = env.render()\n",
    "        break\n",
    "\n",
    "observations = np.stack(observations)\n",
    "actions = np.stack(actions)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "media.show_video(frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax, graphics = do_mpc.graphics.default_plot(lqr.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "- Change the cost matrices of the LQR problem above and try to find the best combinations. \n",
    "- Design an LQR controller for the inverted pendulum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Inverted Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the controller\n",
    "lqr = do_mpc.controller.LQR(inverted_pendulum_lin)\n",
    "\n",
    "# Initialize the parameters\n",
    "env = create_inverted_pendulum_environment()\n",
    "lqr.settings.t_step = env.dt\n",
    "lqr.settings.n_horizon = None  # infinite horizon\n",
    "\n",
    "# Setting the objective\n",
    "Q = np.diag([100, 0.1])\n",
    "R = np.diag([0])\n",
    "lqr.set_objective(Q=Q, R=R)\n",
    "\n",
    "# lqr setup\n",
    "lqr.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define set point\n",
    "xss = np.array([0.0, 0.0]).reshape(-1, 1)\n",
    "lqr.set_setpoint(xss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "max_steps = 500\n",
    "env = create_inverted_pendulum_environment(max_steps=max_steps)\n",
    "initial_observation, _ = env.reset()\n",
    "\n",
    "observation = initial_observation.copy()\n",
    "observations = [observation]\n",
    "actions = []\n",
    "\n",
    "for _ in range(max_steps):\n",
    "    action = lqr.make_step(observation[[1, 3]].reshape(-1, 1)).ravel()\n",
    "    actions.append(action)\n",
    "    observation, _, terminated, truncated, _ = env.step(action)\n",
    "    observations.append(observation)\n",
    "    if terminated or truncated:\n",
    "        frames = env.render()\n",
    "        break\n",
    "\n",
    "observations = np.stack(observations)\n",
    "actions = np.stack(actions)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "media.show_video(frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax, graphics = do_mpc.graphics.default_plot(lqr.data, aux_list=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Predictive Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Unfortunately, the analytically convenient linear quadratic problem formulations are often not satisfactory. There are two main reasons for this:\n",
    "\n",
    "- The system may be nonlinear, and it may be inappropriate to use for\n",
    "  control purposes. Moreover, some of the control variables may be naturally\n",
    "  discrete, and this is incompatible with the linear system viewpoint.\n",
    "  \n",
    "- There may be control and/or state constraints, which are not handled\n",
    "  adequately through quadratic penalty terms in the cost function. For\n",
    "  example, the motion of a car may be constrained by the presence of\n",
    "  obstacles and hardware limitations.\n",
    "  The solution obtained from a linear quadratic model may not be suitable for such\n",
    "  a problem, because quadratic penalties treat constraints \"softly\"\n",
    "  and may produce trajectories that violate the constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A major difference between MPC and finite-state stochastic control problems\n",
    "that are popular in the RL/artificial intelligence literature is that in MPC\n",
    "the state and control spaces are continuous/infinite, such as for example\n",
    "in self-driving cars, the control of aircraft and drones, or the operation of\n",
    "chemical processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Iterative Linear Quadratic Regulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Differential Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mass-Spring-Damper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpc_params = {\n",
    "    \"n_robust\": 0,\n",
    "    \"n_horizon\": 20,\n",
    "    \"t_step\": env.dt,\n",
    "    \"store_full_solution\": True,\n",
    "}\n",
    "\n",
    "xss = np.array([0.2, 0.0])\n",
    "distance_cost = casadi.sumsqr(mass_spring_damper.x.cat - xss)\n",
    "terminal_cost = distance_cost\n",
    "stage_cost = distance_cost\n",
    "input_penalty = 0.0\n",
    "\n",
    "mpc = do_mpc.controller.MPC(mass_spring_damper)\n",
    "mpc.set_param(**mpc_params)\n",
    "mpc.set_objective(mterm=terminal_cost, lterm=stage_cost)\n",
    "mpc.set_rterm(force=input_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_max = 2.0\n",
    "u_max = 20\n",
    "\n",
    "# lower and upper bounds of the states\n",
    "mpc.bounds[\"lower\", \"_x\", \"position\"] = -x_max\n",
    "mpc.bounds[\"upper\", \"_x\", \"position\"] = x_max\n",
    "\n",
    "# lower and upper bounds of the input\n",
    "mpc.bounds[\"lower\", \"_u\", \"force\"] = -u_max\n",
    "mpc.bounds[\"upper\", \"_u\", \"force\"] = u_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpc.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpc.set_initial_guess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "max_steps = 300\n",
    "env = create_mass_spring_damper_environment(max_steps=max_steps)\n",
    "observation, _ = env.reset()\n",
    "\n",
    "for _ in range(max_steps):\n",
    "    action = mpc.make_step(observation).ravel()\n",
    "    observation, _, terminated, truncated, _ = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        frames = env.render()\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "media.show_video(frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax, graphics = do_mpc.graphics.default_plot(mpc.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def update(t_ind):\n",
    "    graphics.plot_results(t_ind)\n",
    "    graphics.plot_predictions(t_ind)\n",
    "\n",
    "\n",
    "frames_idx = [int(i * len(frames) / 50) for i in range(50)]\n",
    "anim = FuncAnimation(fig, update, frames=frames_idx, repeat=False, interval=300)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "- Design an MPC controller for:\n",
    "  - The linearized inverted pendulum.\n",
    "  - The non-linear inverted pendulum.\n",
    "- For each case, try different cost functions:\n",
    "  - $\\sum \\theta^2$\n",
    "  - $\\sum |\\theta|$\n",
    "  - $E_{\\text{kinetic}} - E_{\\text{potential}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Linear Inverted Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "\n",
    "energy_cost = inverted_pendulum_lin.aux[\"E_kinetic\"] - inverted_pendulum_lin.aux[\"E_potential\"]\n",
    "xss = np.array([0.0, 0.0])\n",
    "# distance_cost = casadi.sumsqr(inverted_pendulum_lin.x.cat - xss)\n",
    "distance_cost = casadi.norm_1(inverted_pendulum_lin.x.cat - xss)\n",
    "terminal_cost = distance_cost\n",
    "stage_cost = distance_cost\n",
    "input_penalty = 1e-4\n",
    "\n",
    "mpc_params = {\n",
    "    \"n_robust\": 0,\n",
    "    \"n_horizon\": 20,\n",
    "    \"t_step\": env.dt,\n",
    "    \"store_full_solution\": True,\n",
    "}\n",
    "mpc = do_mpc.controller.MPC(inverted_pendulum_lin)\n",
    "mpc.set_param(**mpc_params)\n",
    "mpc.set_objective(mterm=terminal_cost, lterm=stage_cost)\n",
    "mpc.set_rterm(force=input_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "u_max = 3\n",
    "\n",
    "# lower and upper bounds of the input\n",
    "mpc.bounds[\"lower\", \"_u\", \"force\"] = -u_max\n",
    "mpc.bounds[\"upper\", \"_u\", \"force\"] = u_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpc.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpc.x0 = np.zeros(2)\n",
    "mpc.set_initial_guess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "max_steps = 300\n",
    "env = create_inverted_pendulum_environment(max_steps=max_steps)\n",
    "observation, _ = env.reset()\n",
    "\n",
    "for _ in range(max_steps):\n",
    "    action = mpc.make_step(observation[[1, 3]]).ravel()\n",
    "    observation, _, terminated, truncated, _ = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        frames = env.render()\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "media.show_video(frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax, graphics = do_mpc.graphics.default_plot(mpc.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def update(t_ind):\n",
    "    graphics.plot_results(t_ind)\n",
    "    graphics.plot_predictions(t_ind)\n",
    "\n",
    "\n",
    "frames_idx = [int(i * len(frames) / 50) for i in range(50)]\n",
    "anim = FuncAnimation(fig, update, frames=frames_idx, repeat=False, interval=500)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Non-Linear Inverted Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "\n",
    "energy_cost = inverted_pendulum.aux[\"E_kinetic\"] - inverted_pendulum.aux[\"E_potential\"]\n",
    "distance_cost = casadi.bilin(np.diag([1, 1000, 0, 0]), inverted_pendulum.x.cat)\n",
    "terminal_cost = distance_cost\n",
    "stage_cost = distance_cost\n",
    "input_penalty = 0\n",
    "\n",
    "mpc_params = {\n",
    "    \"n_robust\": 0,\n",
    "    \"n_horizon\": 30,\n",
    "    \"t_step\": env.dt,\n",
    "    \"store_full_solution\": True,\n",
    "}\n",
    "mpc = do_mpc.controller.MPC(inverted_pendulum)\n",
    "mpc.set_param(**mpc_params)\n",
    "mpc.set_objective(mterm=terminal_cost, lterm=stage_cost)\n",
    "mpc.set_rterm(force=input_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_max = 1.0\n",
    "mpc.bounds[\"lower\", \"_x\", \"position\"] = -x_max\n",
    "mpc.bounds[\"upper\", \"_x\", \"position\"] = x_max\n",
    "\n",
    "# lower and upper bounds of the input\n",
    "u_max = 3\n",
    "mpc.bounds[\"lower\", \"_u\", \"force\"] = -u_max\n",
    "mpc.bounds[\"upper\", \"_u\", \"force\"] = u_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpc.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpc.x0 = np.zeros(4)\n",
    "mpc.set_initial_guess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "max_steps = 300\n",
    "env = create_inverted_pendulum_environment(max_steps=max_steps)\n",
    "observation, _ = env.reset()\n",
    "\n",
    "for _ in range(max_steps):\n",
    "    action = mpc.make_step(observation).ravel()\n",
    "    observation, _, terminated, truncated, _ = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        frames = env.render()\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "media.show_video(frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax, graphics = do_mpc.graphics.default_plot(mpc.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def update(t_ind):\n",
    "    graphics.plot_results(t_ind)\n",
    "    graphics.plot_predictions(t_ind)\n",
    "\n",
    "\n",
    "frames_idx = [int(i * len(frames) / 30) for i in range(30)]\n",
    "anim = FuncAnimation(fig, update, frames=frames_idx, repeat=False, interval=500)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell",
     "remove-cell-nbconv"
    ]
   },
   "source": [
    "<img src=\"_static/images/aai-institute-cover.svg\" alt=\"Snow\" style=\"width:100%;\">\n",
    "<div class=\"md-slide title\">Thank you for the attention!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "- [<b id=\"slotine_applied_1991\">[Slotine 1991]</b>](#slotine_applied_1991-back) [Applied nonlinear control.](https://www.academia.edu/download/33582713/Applied_Nonlinear_Control_Slotine.pdf) Slotine, Jean-Jacques E., and Weiping Li. Vol. 199, no. 1. Englewood Cliffs, NJ: Prentice hall. 1991.\n",
    "\n",
    "- [<b id=\"grune_nonlinear_2017\">[Lars Nonlinear 2017]</b>](#grune_nonlinear_2017-back) [Nonlinear model predictive control.](https://link.springer.com/chapter/10.1007/978-3-319-46024-6_3) GrÃ¼ne, Lars, JÃ¼rgen Pannek, Lars GrÃ¼ne, and JÃ¼rgen Pannek. Springer International Publishing, 2017.\n",
    "\n",
    "- [<b id=\"bertsekas_lessons_2022\">[Bertsektas, Dimitri P, 2022]</b>](#bertsekas_lessons_2022-back) [Lessons from AlphaZero for Optimal, Model Predictive, and Adaptive Control](http://web.mit.edu/dimitrib/www/LessonsfromAlphazero.pdf) - Dimitri P. Bertsektas. 2022.\n",
    "- [<b id=\"spencer_optimal_2023\">[Spencer et al. 2023]</b>](#spencer_optimal_2023-back) [AA 203: Optimal and Learning-Based Control.](https://stanfordasl.github.io/aa203/sp2223/) Optimal control solution techniques for systems with known and unknown dynamics. 2023."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "rise": {
   "footer": "<img src='_static/images/aai-logo.png' alt='logo' height='50em'>",
   "header": "<img src='_static/images/transferlab-logo.svg' alt='logo' height='20em' />",
   "theme": "white"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "148px",
    "width": "256px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "563.2px",
    "left": "125px",
    "top": "116.469px",
    "width": "315.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
