{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input",
     "remove-output",
     "remove-input-nbconv",
     "remove-output-nbconv"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext training_rl\n",
    "%set_random_seed 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%presentation_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_latex_macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Protocol\n",
    "\n",
    "import casadi\n",
    "import control as ct\n",
    "import do_mpc\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotx\n",
    "import mediapy as media\n",
    "import mujoco\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from gymnasium import Env\n",
    "from IPython.display import HTML\n",
    "from ipywidgets import interact, widgets\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from training_rl.control import (\n",
    "    create_inverted_pendulum_environment,\n",
    "    create_mass_spring_damper_environment,\n",
    "    MassSpringDamperParameters,\n",
    "    InvertedPendulumParameters,\n",
    "    create_shortest_path_graph,\n",
    "    plot_shortest_path_graph,\n",
    "    plot_all_paths_graph,\n",
    "    animate_mass_spring_damper_simulation,\n",
    "    animate_inverted_pendulum_simulation,\n",
    ")\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "sns.set_theme()\n",
    "plt.rcParams[\"figure.figsize\"] = [9, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"_static/images/aai-institute-cover.svg\" alt=\"presentation first slide\" style=\"width:100%;\">\n",
    "<div class=\"md-slide title\">Control and Planning</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In previous sections, we have designed feedback controllers for various systems with the goal of regulating the system output to a desired setpoint. Specifically, we utilized Fullstate Feedback and PID controllers. While these simple controllers can effectively regulate many systems, they have limitations that prevent high performance control for more complex systems.\n",
    "\n",
    "First, these controllers have a fixed, static gain that does not change over time. This limits their ability to adapt to changing system dynamics or disturbances. Second, after developing a mathematical model of the system dynamics, we did not actually utilize the model in the controller design. A model-based approach could allow us to leverage our understanding of the system to improve control performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One ubiquitous challenge in control system design is the presence of control input constraints. Actuators in physical systems inherently have limits on their amplitude and rate of change. For example, a motor has maximum torque and acceleration limits. If control input constraints are ignored in the controller design, the resulting control inputs may saturate the actuators, degrading closed-loop performance.\n",
    "\n",
    "There are two main strategies to address control input constraints:\n",
    "\n",
    "- Reduce the performance requirements to levels achievable with a linear controller without violating the constraints.\n",
    "- Directly account for the constraints by modifying the control design and online optimization of the control input.   For example, model predictive control utilizes the system model to predict future behavior and optimize the control input while satisfying constraints.\n",
    "\n",
    "In subsequent sections, we will explore model-based and optimization-based control techniques to overcome the limitations of basic controllers. Properly managing control input constraints is crucial to achieving high performance in real control systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mass-Spring-Damper Model\n",
    "\n",
    "\n",
    "<div>\n",
    "<figure style=\"float: left; width: 50%;\">\n",
    "    <img src=\"_static/images/20_mass_spring_damper.svg\" width=\"50%\"/>\n",
    "    <figcaption>\n",
    "        Classic model used for deriving the equations of a mass spring damper model <a href=\"#wiki_mass_spring_damper\"><b id=\"wiki_mass_spring_damper-back\">[Wiki Mass-Spring-Damper, 2023]</b></a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "<div style=\"float: left; width: 40%;\">\n",
    "    \n",
    "- $z(t)$: Distance along the vertical axis from some reference point.\n",
    "- $m$: Mass of the object.\n",
    "- $\\lambda$: Coefficient of elasticity.\n",
    "- $l$: Length of spring.\n",
    "- $k = \\frac{\\lambda}{l}$\n",
    "- $c$: Damping coefficient.\n",
    "- $f(t)$: Force applied on the object.\n",
    "- $g$: Gravity.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The system has linear state-space model with matrices:\n",
    "\n",
    "$$\n",
    "A\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "-\\frac{k}{m} & -\\frac{c}{m}\\\\\n",
    "\\end{bmatrix};\n",
    "B\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\frac{1}{m}\\\\\n",
    "\\end{bmatrix};\n",
    "C = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "\\end{bmatrix};\n",
    "D = \\begin{bmatrix}\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "msd_parameters = MassSpringDamperParameters()\n",
    "m = msd_parameters.m\n",
    "c = msd_parameters.c\n",
    "k = msd_parameters.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Dynamics matrix\n",
    "A = np.array(\n",
    "    [\n",
    "        [0, 1],\n",
    "        [-k / m, -c / m],\n",
    "    ]\n",
    ")\n",
    "# Input matrix\n",
    "B = np.array([[0, 1 / m]]).transpose()\n",
    "# Output matrices\n",
    "C = np.array([[1, 0], [0, 1]])\n",
    "D = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mass_spring_damper = do_mpc.model.LinearModel(\"continuous\")\n",
    "mass_spring_damper.set_variable(var_type=\"_x\", var_name=\"position\")\n",
    "mass_spring_damper.set_variable(var_type=\"_x\", var_name=\"velocity\")\n",
    "mass_spring_damper.set_variable(var_type=\"_u\", var_name=\"force\")\n",
    "mass_spring_damper.setup(A, B, C, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_mass_spring_damper_environment()\n",
    "mass_spring_damper = mass_spring_damper.discretize(env.dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Inverted Pendulum\n",
    "\n",
    "<div>\n",
    "<figure style=\"float: left; width: 40%;\">\n",
    "    <img src=\"_static/images/20_inverted_pendulum.svg\" width=\"50%\"/>\n",
    "    <figcaption>\n",
    "        Inverted pendulum model <a href=\"#goodwin_control_2000\"><b id=\"goodwin_control_2000-back\">[Goodwin et al., 2000]</b></a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "<div style=\"float: left; width: 50%\">\n",
    "    \n",
    "- $y(t)$: distance along the horizontal axis from some reference point.\n",
    "- $\\theta(t)$: angle of the pendulum.\n",
    "- $M$: mass of the cart.\n",
    "- $m$: mass of the pendulum (assumed to be concentrated at the tip).\n",
    "- $l$: length of the pendulum.\n",
    "- $f(t)$: force applied on the cart.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The system has the following full non-linear state space model:\n",
    "\n",
    "$$\n",
    "\\dot{X}(t) = \\begin{bmatrix}\n",
    "\\dot{x_1}(t) \\\\ \\dot{x_2}(t) \\\\ \\dot{x_3}(t) \\\\ \\dot{x_4}(t)\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "x_2(t) \\\\\n",
    "x_4(t) \\\\\n",
    "\\frac{1}{\\lambda_m + \\sin^2 x_2(t)} \\left[\n",
    "\\frac{u(t)}{m} + x_4(t)^2 l \\sin x_2(t) - g \\cos x_2(t) \\sin x_2(t)\n",
    "\\right] \\\\\n",
    "\\frac{1}{l\\lambda_m + \\sin^2 x_2(t)} \\left[\n",
    "-\\frac{u(t)}{m}\\cos x_2(t) + x_4(t)^2 l \\sin x_2(t) \\cos x_2(t) + (1 - \\lambda_m) \\sin x_2(t)\n",
    "\\right] \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And the following partial (pendulum angle only) non-linear state space model:\n",
    "\n",
    "$$\n",
    "\\dot{X}(t) = \\begin{bmatrix}\n",
    "\\dot{x_1}(t) \\\\ \\dot{x_2}(t)\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "x_2(t) \\\\\n",
    "\\frac{1}{l\\lambda_m + \\sin^2 x_1(t)} \\left[\n",
    "-\\frac{u(t)}{m}\\cos x_1(t) + x_2(t)^2 l \\sin x_1(t) \\cos x_1(t) + (1 - \\lambda_m) \\sin x_1(t)\n",
    "\\right] \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And the following linearized (around $\\theta = 0$ and $\\dot{\\theta} = 0$) state space model:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "\\frac{(M + m)g}{Ml} & 0\\\\\n",
    "\\end{bmatrix};\n",
    "B = \\begin{bmatrix}\n",
    "0 \\\\ -\\frac{1}{Ml}\n",
    "\\end{bmatrix};\n",
    "C = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "\\end{bmatrix};\n",
    "D = \\begin{bmatrix}\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "\n",
    "ip_parameters = InvertedPendulumParameters(\n",
    "    l=env.model.geom_pos[2, 2],\n",
    "    m=env.model.body_mass[2],\n",
    "    M=env.model.body_mass[1],\n",
    ")\n",
    "g = ip_parameters.g\n",
    "l = ip_parameters.l\n",
    "m = ip_parameters.m\n",
    "M = ip_parameters.M\n",
    "lambda_m = M / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Dynamics matrix\n",
    "A = np.array(\n",
    "    [\n",
    "        [0, 1],\n",
    "        [(1 + lambda_m) * g / (lambda_m * l), 0],\n",
    "    ]\n",
    ")\n",
    "# Input matrix\n",
    "B = np.array([[0, -1 / (M * l)]]).transpose()\n",
    "# Output matrices\n",
    "C = np.array([[1, 0], [0, 1]])\n",
    "D = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum_lin = do_mpc.model.LinearModel(\"continuous\")\n",
    "theta = inverted_pendulum_lin.set_variable(var_type=\"_x\", var_name=\"theta\")\n",
    "dtheta = inverted_pendulum_lin.set_variable(var_type=\"_x\", var_name=\"dtheta\")\n",
    "inverted_pendulum_lin.set_variable(var_type=\"_u\", var_name=\"force\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We also define the pendulum's kinetic and potential energies:\n",
    "\n",
    "$E_{\\text{kinetic}} = \\frac{1}{2} m \\left( (l x_2 \\cos(x_1))^{2} + (l x_2 \\sin(x_1))^{2} \\right)$\n",
    "    \n",
    "$E_{\\text{potential}} = m g  l \\cos(x_1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Energies\n",
    "E_kin = 0.5 * m * ((l * dtheta * casadi.cos(theta)) ** 2 + (l * dtheta * casadi.sin(theta)) ** 2)\n",
    "E_pot = m * g * l * casadi.cos(theta)\n",
    "inverted_pendulum_lin.set_expression(\"E_kinetic\", E_kin)\n",
    "inverted_pendulum_lin.set_expression(\"E_potential\", E_pot);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum_lin.setup(A, B, C, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "inverted_pendulum_lin = inverted_pendulum_lin.discretize(env.dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We also define the full non-linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum = do_mpc.model.Model(\"continuous\")\n",
    "\n",
    "position = inverted_pendulum.set_variable(var_type=\"_x\", var_name=\"position\")\n",
    "theta = inverted_pendulum.set_variable(var_type=\"_x\", var_name=\"theta\")\n",
    "velocity = inverted_pendulum.set_variable(var_type=\"_x\", var_name=\"velocity\")\n",
    "dtheta = inverted_pendulum.set_variable(var_type=\"_x\", var_name=\"dtheta\")\n",
    "u = inverted_pendulum.set_variable(var_type=\"_u\", var_name=\"force\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "denominator = lambda_m + casadi.sin(theta) ** 2\n",
    "nominator = (\n",
    "    u / m * casadi.cos(theta)\n",
    "    + dtheta**2 * l * casadi.sin(theta)\n",
    "    - g * casadi.sin(theta) * casadi.cos(theta)\n",
    ")\n",
    "\n",
    "inverted_pendulum.set_rhs(\"position\", velocity)\n",
    "inverted_pendulum.set_rhs(\"velocity\", nominator / denominator)\n",
    "\n",
    "denominator = l * lambda_m + casadi.sin(theta) ** 2\n",
    "nominator = (\n",
    "    -u / m * casadi.cos(theta)\n",
    "    + dtheta**2 * l * casadi.sin(theta) * casadi.cos(theta)\n",
    "    + (1 - lambda_m) * casadi.sin(theta)\n",
    ")\n",
    "\n",
    "inverted_pendulum.set_rhs(\"theta\", dtheta)\n",
    "inverted_pendulum.set_rhs(\"dtheta\", nominator / denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And kinetic and potential energies:\n",
    "\n",
    "$E_{\\text{kinetic}} = E_{\\text{kinetic, cart}} + E_{\\text{kinetic, pendulum}}$\n",
    "    \n",
    "$E_{\\text{kinetic, cart}} = \\frac{1}{2} M x_3^{2}$\n",
    "    \n",
    "$E_{\\text{kinetic, pendulum}} = \\frac{1}{2} m \\left( (x_3 + l x_4 \\cos(x_2))^{2} + (l x_4 \\sin(x_2))^{2} \\right)$\n",
    "    \n",
    "$E_{\\text{potential}} = m g  l \\cos(x_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Energies\n",
    "E_kin = 0.5 * M * velocity**2 + 0.5 * m * (\n",
    "    (velocity + l * dtheta * casadi.cos(theta)) ** 2 + (l * dtheta * casadi.sin(theta)) ** 2\n",
    ")\n",
    "E_pot = m * g * l * casadi.cos(theta)\n",
    "inverted_pendulum.set_expression(\"E_kinetic\", E_kin)\n",
    "inverted_pendulum.set_expression(\"E_potential\", E_pot);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "inverted_pendulum.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class FeedbackController(Protocol):\n",
    "    def control(self, observation: NDArray) -> NDArray:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EnvironmentSimulationResults:\n",
    "    frames: list[NDArray]\n",
    "    observations: NDArray\n",
    "    actions: NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def simulate_environment(\n",
    "    env: Env,\n",
    "    *,\n",
    "    controller: FeedbackController,\n",
    "    max_steps: int = 500,\n",
    ") -> EnvironmentSimulationResults:\n",
    "    if controller is None:\n",
    "        controller = RandomController(env)\n",
    "\n",
    "    observation, _ = env.reset()\n",
    "    actions = []\n",
    "    observations = [observation]\n",
    "\n",
    "    for _ in range(max_steps):\n",
    "        action = controller.act(observation)\n",
    "        observation, _, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "        observations.append(observation)\n",
    "        actions.append(action)\n",
    "\n",
    "        # Check if we need to stop the simulation\n",
    "        if terminated or truncated:\n",
    "            frames = env.render()\n",
    "            env.reset()\n",
    "            break\n",
    "    env.close()\n",
    "\n",
    "    actions = np.stack(actions)\n",
    "    observations = np.stack(observations)\n",
    "\n",
    "    return SimulationResults(\n",
    "        frames=frames,\n",
    "        observations=observations,\n",
    "        actions=actions,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_mass_spring_damper_environment()\n",
    "mass_spring_damper_simulator = do_mpc.simulator.Simulator(mass_spring_damper)\n",
    "mass_spring_damper_simulator.set_param(t_step=env.dt)\n",
    "mass_spring_damper_simulator.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "inverted_pendulum_lin_simulator = do_mpc.simulator.Simulator(inverted_pendulum_lin)\n",
    "inverted_pendulum_lin_simulator.set_param(t_step=env.dt)\n",
    "inverted_pendulum_lin_simulator.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "inverted_pendulum_simulator = do_mpc.simulator.Simulator(inverted_pendulum)\n",
    "inverted_pendulum_simulator.set_param(t_step=env.dt)\n",
    "inverted_pendulum_simulator.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimal Control\n",
    "\n",
    "Optimal control theory is a branch of control theory that deals with finding a control for a dynamical system over a period of time such that an objective function is optimized. The fundamental idea in optimal control is to formulate the goal of control as the long-term optimization of a scalar cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The optimal control problem is to find a control $u^* \\in \\mathbf{U}$ which causes the system $\\dot{x}(t) = f(x(t), u(t))$ to follow a trajectory $x^* \\in \\mathbf{X}$ that minimizes the cost (performance measure):\n",
    "\n",
    "\n",
    "### Continuous-time\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\displaystyle  \\min_{x, u} & J(x, u) & \\text{(cost)}\\\\\n",
    "\\text{subject to} & \\dot{x}(t) = f(x(t), u(t)) & \\text{(dynamical feasibility)}\\\\\n",
    "& x(t_0) = x_0, x(T) \\in \\mathbf{X_T} & \\text{(boundary conditions)}\\\\\n",
    "& x(t) \\in \\mathbf{X} , \\forall t \\in [0, T] & \\text{(state constraints)}\\\\\n",
    "& u(t) \\in \\mathbf{U}, \\forall t \\in [0, T] & \\text{(input constraints)}\\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Discrete-time\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\displaystyle  \\min_{x, u} & J(x, u) & \\text{(cost)}\\\\\n",
    "\\text{subject to} & x_{t+1} = f(x_t, u_t) & \\text{(dynamical feasibility)}\\\\\n",
    "& x_{t_0} = x_0, x_N \\in \\mathbf{X_N} & \\text{(boundary conditions)}\\\\\n",
    "& x_t \\in \\mathbf{X} , \\forall t \\in \\{0, 1, \\dots , N - 1\\} & \\text{(state constraints)}\\\\\n",
    "& u_t \\in \\mathbf{U}, \\forall t \\in \\{0, 1, \\dots , N - 1\\} & \\text{(input constraints)}\\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Finite Horizon \n",
    "\n",
    "- Continuous-time:\n",
    "\n",
    "$$\n",
    "J_{T}(x_0, u) = l_f(x(T)) + \\int \\limits_{0}^{T} l(x(t), u(t)) dt\n",
    "$$\n",
    "\n",
    "- Discrete-time:\n",
    "\n",
    "$$\n",
    "J_N(x_0, u) = l_f(x_N) + \\sum \\limits_{k = 0}^{N-1} l(x_k, u_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Infinite Horizon\n",
    "\n",
    "- Continuous-time:\n",
    "\n",
    "$$\n",
    "J(x_0, u) = \\int \\limits_{0}^{\\infty} l(x(t), u(t)) dt\n",
    "$$\n",
    "\n",
    "- Discrete-time:\n",
    "\n",
    "$$\n",
    "J(x_0, u) = \\sum \\limits_{k = 0}^{\\infty} l(x_k, u_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This approach is powerful for a number of reasons. First and foremost, it is very general - allowing us to specify the goal of control equally well for fully- or under-actuated, linear or nonlinear, deterministic or stochastic, and continuous or discrete systems. Second, it permits concise descriptions of potentially very complex desired behaviours, specifying the goal of control as a scalar objective (plus a list of constraints)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Common moptimal control methods are Dynamic Programming (DP), Pontryagin’s Minimum Principle (PMP), and Hamilton-Jacobi-Bellman (HJB) equations.\n",
    "\n",
    "- DP is helpful where the number of states is limited and the dynamics are known. It divides an optimal control issue into smaller subproblems and recursively solves each.\n",
    "\n",
    "- PMP, another optimal control method, employs the Hamiltonian of the system to find the optimal control input. Problems involving continuous states and control inputs benefit most from it.\n",
    "\n",
    "- Another optimal control algorithm is the HJB equation which uses partial differential equations to find the value function of the system. HJB is also useful for problems with continuous states and control inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Choosing the cost function\n",
    "\n",
    "Choosing a cost function means translating the system's desired physical state into a mathematical formulation.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Minimum-time problems: $J = t_f - t_0$\n",
    "- Terminal control problems: $J = || x(t_f) - r(t_f) ||^2$\n",
    "- Minimum control-effort problems: $J = \\sum \\limits_{k = t_0}^{t_f} |u(t_k)|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[do-mpc](https://www.do-mpc.com/en/latest/) uses [CasADi](https://web.casadi.org/python-api/) (an open-source tool for nonlinear optimization and algorithmic differentiation) for the modeling part and for the different cost functions. Here's a table of useful operators:\n",
    "\n",
    "| Operator | Description |Equation |\n",
    "| --- | --- | --- |\n",
    "| [casadi.sumsqr(x)](https://web.casadi.org/python-api/#casadi.casadi.sumsqr) | Squared-sum | $\\sum x_i^2$ |\n",
    "| [casadi.norm_2(x)](https://web.casadi.org/python-api/#casadi.casadi.norm_2) | $L_2$-norm | $\\sqrt{\\sum x_i^2}$ |\n",
    "| [casadi.norm_1(x)](https://web.casadi.org/python-api/#casadi.casadi.norm_1) | $L_1$-norm | $\\sum |x_i|$ |\n",
    "| [casadi.bilin(A, x)](https://web.casadi.org/python-api/#casadi.casadi.bilin) | Quadratic Form | $x^T A x$ |\n",
    "| [casadi.bilin(A, x, y)](https://web.casadi.org/python-api/#casadi.casadi.bilin) | Bilinear Form | $x^T A y$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Questions\n",
    "\n",
    "- What are possible cost functions for the 2 systems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dynamic Programming\n",
    "\n",
    "Dynamic programming (DP) is a method that in general solves optimization problems that involve making a sequence of decisions by determining, for each decision, subproblems that can be solved in like fashion, such that an optimal\n",
    "solution of the original problem can be found from optimal solutions of sub-\n",
    "problems. This method is based on Bellman’s Principle of Optimality, which\n",
    "he phrased as follows:\n",
    "\n",
    "> An optimal policy has the property that whatever the initial state and\n",
    "initial decision are, the remaining decisions must constitute an optimal\n",
    "policy with regard to the state resulting from the first decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dynamic Programming is a very general solution method for problems which have two properties:\n",
    "\n",
    "- Optimal substructure (Principle of optimality applies)\n",
    "  - Optimal solution can be decomposed into subproblems, e.g., shortest path\n",
    "- Overlapping subproblems\n",
    "  - Subproblems recur many times\n",
    "  - Solutions can be cached and reused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dynamic programming is used across a wide variety of domains, e.g.\n",
    "\n",
    "- Scheduling algorithms\n",
    "- Graph algorithms (e.g., shortest path algorithms)\n",
    "- Graphical models in ML (e.g., Viterbi algorithm)\n",
    "- Bioinformatics (e.g., Sequence alignment, Protein folding) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We define the **cost-to-go function** (also known as **optimal value function**) as (for the sake of simplicity we will focus on the discrete-time case):\n",
    "\n",
    "$$\n",
    "V_N(x_0) := \\min_{u \\in \\mathbf{U}} J_N(x_0, u)\n",
    "$$\n",
    "\n",
    "An admissible control sequence $u^*$ is called optimal, if\n",
    "\n",
    "$$\n",
    "V_N(x_0) = J_N(x_0, u^*)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For any feasible $x_0 \\in \\mathbf{X}$ the optimal value function satisfies\n",
    "\n",
    "$$\n",
    "V_N(x_0) = \\displaystyle \\min_{u \\in \\mathbf{U}} l(x_0, u) + V_{N-1}(f(x_0, u))\n",
    "$$\n",
    "\n",
    "Moreover, if $u^*$ is an optimal control, then\n",
    "\n",
    "$$\n",
    "V_N(x_0) = l(x_0, u^*_0) + V_{N-1}(f(x_0, u^*_0))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  DP Algorithm\n",
    "\n",
    "For every initial state $x_0$, the optimal cost is equal to $V_N(x_0)$, given by the last step of the following algorithm, which proceeds backward in time from stage $N-1$ to stage $0$:\n",
    "\n",
    "$$\n",
    "V_0(x_N) = l(x_N)\\\\\n",
    "V_{k+1}(x_{N-k+1}) = \\displaystyle \\min_{u \\in \\mathbf{U}} \\left\\{ l(x_{N-k+1}, u_{N-k+1}) + V_{k}(f(x_{N-k}, u_{N-k})) \\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "G = create_shortest_path_graph()\n",
    "plot_shortest_path_graph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We wish to travel from node A to node G at minimum cost. If the cost represents time then we want to find the shortest path from A to G.\n",
    "\n",
    "- Arrows (edges) indicate the possible movements.\n",
    "- Numbers on edges indicate the cost of moving along an edge.\n",
    "\n",
    "Use Dynamic Programming to solve this problem.\n",
    "\n",
    "> **Hint** Determine all possible paths first and then compute the cost-to-go at each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_all_paths_graph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Each node in this new graph represents a state. We will start from the tail (the last states) and compute recursively the cost for each state transition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We start by determining the cost-to-go for all positions.\n",
    "\n",
    "Let $l(n_1, n_2)$ the cost of going from node $n_1$ to $n_2$ and $V(n)$ be the cost-to-go from node $n$.\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V(\\text{ABDF}) &= l(\\text{ABDF}, \\text{ABDFG}) &= 1\\\\\n",
    "V(\\text{ABE}) &= l(\\text{ABE}, \\text{ABEG}) &= 4\\\\\n",
    "V(\\text{ACF}) &= l(\\text{ACF}, \\text{ACFG}) &= 1\\\\\n",
    "V(\\text{ADF}) &= l(\\text{ADF}, \\text{ADFG}) &= 1\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V(\\text{ABD}) &= \\min \\left[ l(\\text{ABD}, \\text{ABDG}), l(\\text{ABD}, \\text{ABDF}) + V(\\text{ABDF}) \\right]\n",
    "&= \\min \\left[ 8, 5 + 1 \\right] &= 6\n",
    "\\\\\n",
    "V(\\text{AB}) &= \\min \\left[ l(\\text{AB}, \\text{ABD}) + V(\\text{ABD}), l(\\text{AB}, \\text{ABE}) + V(\\text{ABE}) \\right]\n",
    "&= \\min \\left[ 9 + 5, 6 + 4 \\right] &= 10\n",
    "\\\\\n",
    "V(\\text{AC}) &= l(\\text{AC}, \\text{ACF}) + V(\\text{ACF}) &= 2 + 1 &= 3\n",
    "\\\\\n",
    "V(\\text{AD}) &= \\min \\left[ l(\\text{AD}, \\text{ADF}) + V(\\text{ADF}), l(\\text{AD}, \\text{ADG})) \\right]\n",
    "&= \\min \\left[ 5 + 1, 8 \\right] &= 6\n",
    "\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V(\\text{A}) &= \\min \\left[\n",
    "l(\\text{A}, \\text{AB}) + V(\\text{AB}), l(\\text{A}, \\text{AC}) + V(\\text{AC}), l(\\text{A}, \\text{AD}) + V(\\text{AD})\n",
    "\\right]\n",
    "&= \\min \\left[ 1 + 10, 5 + 3, 3 + 6 \\right] &= 8\n",
    "\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The shortest-path is aCFG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_all_paths_graph(G, show_solution=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Quadratic Regulator\n",
    "\n",
    "While solving the optimal control problem (OCP) is very hard in general, there are a few very important special cases where the solutions are very accessible. Most of these involve variants on the case of linear dynamics and quadratic cost. The simplest case, called the linear quadratic regulator (LQR), is formulated as stabilizing a time-invariant linear system to the origin can be solved analytically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a discrete-time linear system described by:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t+1} = A \\mathbf{x}_t + B \\mathbf{u}_t\n",
    "$$\n",
    "\n",
    "where $x\\in \\mathbb {R} ^{n}$ (that is, $x$ is an $n$-dimensional real-valued vector) is the state of the system and $u\\in \\mathbb {R} ^{m}$ is the control input. Given a quadratic cost function for the system, defined as:\n",
    "\n",
    "### Finite-Horizon\n",
    "\n",
    "$$\n",
    "J_0(\\mathbf{x}_0, \\mathbf{u}) = \\frac{1}{2} \\mathbf{x}_N^T Q \\mathbf{x}_N + \\frac{1}{2} \\sum \\limits _{k = 0}^{N - 1}  \\mathbf{x}_k^{T}Q \\mathbf{x}_k + \\mathbf{u}_k^{T} R \\mathbf{u}_k\n",
    "$$\n",
    "\n",
    "With $Q = Q^T \\succeq 0$, $R = R^T \\succeq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Infinite-Horizon\n",
    "\n",
    "$$\n",
    "J(\\mathbf{x}_0, \\mathbf{u}) = \\frac{1}{2} \\sum \\limits _{k = 0}^{\\infty} \\mathbf{x}_k^{T}Q \\mathbf{x}_k + \\mathbf{u}_k^{T} R \\mathbf{u}_k\n",
    "$$\n",
    "\n",
    "With $Q = Q^T \\succeq 0$, $R = R^T \\succeq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's solve this for the finite-horizon case using dynamic programming. We start by setting:\n",
    "\n",
    "$$\n",
    "V_N(\\mathbf{x}_N) = J_N(\\mathbf{x}_N) = \\frac{1}{2} \\mathbf{x}_{N}^T Q \\mathbf{x}_{N} = \\frac{1}{2} \\mathbf{x}_{N}^T P \\mathbf{x}_{N}\n",
    "$$\n",
    "\n",
    "And then proceed backward in time:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V_{N-1}(\\mathbf{x}_{N-1}) &=& \\displaystyle \\min_{\\mathbf{u}_{N-1}} J_{N-1}(\\mathbf{x}_{N-1}, \\mathbf{u}_{N-1})\\\\\n",
    "&=& \\displaystyle \\min_{\\mathbf{u}_{N-1}} \\frac{1}{2} \\left(\n",
    "\\mathbf{x}_{N-1}^{T} Q \\mathbf{x}_{N-1} + \\mathbf{u}_{N-1}^{T} R \\mathbf{u}_{N-1} + \\mathbf{x}_{N}^T P \\mathbf{x}_{N}\n",
    "\\right) \\\\\n",
    "&=& \\displaystyle \\min_{\\mathbf{u}_{N-1}} \\frac{1}{2} \\left(\n",
    "\\mathbf{x}_{N-1}^{T} Q \\mathbf{x}_{N-1} + \\mathbf{u}_{N-1}^{T} R \\mathbf{u}_{N-1} + (A\\mathbf{x}_{N-1} + B\\mathbf{u}_{N-1})^T P (A\\mathbf{x}_{N-1} + B\\mathbf{u}_{N-1})\n",
    "\\right)\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Taking the gradient with respect to $\\mathbf{u}_{N-1}$:\n",
    "\n",
    "$$\n",
    "\\displaystyle \\nabla_{\\mathbf{u}_{N-1}} J_{N-1}(\\mathbf{x}_{N-1}, \\mathbf{u}_{N-1}) = \n",
    "R \\mathbf{u}_{N-1} + B^T P (A \\mathbf{x}_{N-1} + B \\mathbf{u}_{N - 1}) = 0\n",
    "$$\n",
    "\n",
    "Gives us the following optimal feedback control at step $N - 1$:\n",
    "\n",
    "$$\n",
    "\\mathbf{u}^*_{N-1} = -(R + B^T P B)^{-1} B^T P B \\mathbf{x}_{N-1} = - K \\mathbf{x}_{N-1}\n",
    "$$\n",
    "\n",
    "With $K = (R + B^T P B)^{-1} B^T P B$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The optimal cost-to-go is then:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V_{N-1}(\\mathbf{x}_{N-1}) &= J_{N-1}(\\mathbf{x}_{N-1}, \\mathbf{u}^*_{N-1}) \\\\\n",
    "&= \\frac{1}{2}  \\left(\n",
    "\\mathbf{x}_{N-1}^{T} Q \\mathbf{x}_{N-1} + \\mathbf{u}_{N-1}^{*T} R \\mathbf{u}^{*}_{N-1} + \\mathbf{x}_{N}^T P \\mathbf{x}_{N}\n",
    "\\right)\\\\\n",
    "&= \\frac{1}{2}  \\left(\n",
    "\\mathbf{x}_{N-1}^{T} Q \\mathbf{x}_{N-1} + \\mathbf{u}_{N-1}^{*T} R \\mathbf{u}^{*}_{N-1} + (A\\mathbf{x}_{N-1} + B\\mathbf{u}_{N-1})^T P (A\\mathbf{x}_{N-1} + B\\mathbf{u}_{N-1})\n",
    "\\right)\\\\\n",
    "&= \\frac{1}{2}  \\left(\n",
    "\\mathbf{x}_{N-1}^{T} Q \\mathbf{x}_{N-1} + \\mathbf{x}_{N-1}^{T} K^T R K \\mathbf{x}_{N-1} + \\mathbf{x}_{N-1}^T(A - BK)^T P (A - BK)\\mathbf{x}_{N-1}\n",
    "\\right)\\\\\n",
    "&= \\frac{1}{2}  \n",
    "\\mathbf{x}_{N-1}^{T} \\left(\n",
    "Q + A^{T}PA-(A^{T}PB)(R+B^{T}PB)^{-1}(B^{T}PA)\n",
    "\\right) \\mathbf{x}_{N-1}\n",
    "\\\\\n",
    "&:= \\frac{1}{2} \\mathbf{x}_{N-1}^T P \\mathbf{x}_{N-1}\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The last step is needed to ensure that the derivation works recursively for all steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "and $P$ is found by solving the discrete time algebraic Riccati equation (DARE):\n",
    "\n",
    "$$\n",
    "Q + A^{T}PA-(A^{T}PB)(R+B^{T}PB)^{-1}(B^{T}PA) = P.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mass-Spring-Damper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the controller\n",
    "lqr = do_mpc.controller.LQR(mass_spring_damper)\n",
    "\n",
    "# Initialize the parameters\n",
    "env = create_mass_spring_damper_environment()\n",
    "lqr.settings.t_step = env.dt\n",
    "lqr.settings.n_horizon = None  # infinite horizon\n",
    "\n",
    "# Setting the objective\n",
    "Q = np.diag([100, 0])\n",
    "R = np.diag([1e-3])\n",
    "lqr.set_objective(Q=Q, R=R)\n",
    "\n",
    "# lqr setup\n",
    "lqr.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define set point\n",
    "xss = np.array([0.1, 0.0]).reshape(-1, 1)\n",
    "lqr.set_setpoint(xss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### SImulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "lqr.reset_history()\n",
    "mass_spring_damper_simulator.reset_history()\n",
    "x0 = np.zeros((2, 1))\n",
    "mass_spring_damper_simulator.x0 = x0\n",
    "for _ in range(50):\n",
    "    u0 = lqr.make_step(x0)\n",
    "    x0 = mass_spring_damper_simulator.make_step(u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "animate_mass_spring_damper_simulation(lqr.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class LQRController:\n",
    "    def __init__(self, lqr: do_mpc.controller.LQR) -> None:\n",
    "        self.lqr = lqr\n",
    "        self.lqr.reset_history()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return lqr.make_step(observation.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "max_steps = 100\n",
    "env = create_mass_spring_damper_environment(max_steps=max_steps)\n",
    "controller = LQRController(lqr)\n",
    "results = simulate_environment(env, max_steps=max_steps, controller=controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "media.show_video(results.frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, ax, graphics = do_mpc.graphics.default_plot(lqr.data)\n",
    "ax[0].hlines(xss[0], lqr.data._time[0], lqr.data._time[-1], \"r\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "- Change the cost matrices of the LQR problem above and try to find the best combinations. \n",
    "- Design an LQR controller for the inverted pendulum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Inverted Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the controller\n",
    "lqr = do_mpc.controller.LQR(inverted_pendulum_lin)\n",
    "\n",
    "# Initialize the parameters\n",
    "env = create_inverted_pendulum_environment()\n",
    "lqr.settings.t_step = env.dt\n",
    "lqr.settings.n_horizon = None  # infinite horizon\n",
    "\n",
    "# Setting the objective\n",
    "Q = np.diag([100, 0])\n",
    "R = np.diag([10])\n",
    "lqr.set_objective(Q=Q, R=R)\n",
    "\n",
    "# lqr setup\n",
    "lqr.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define set point\n",
    "xss = np.array([0.0, 0.0]).reshape(-1, 1)\n",
    "lqr.set_setpoint(xss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "lqr.reset_history()\n",
    "inverted_pendulum_lin_simulator.reset_history()\n",
    "x0 = np.zeros((2, 1))\n",
    "x0[0] = 0.2\n",
    "inverted_pendulum_lin_simulator.x0 = x0\n",
    "for k in range(50):\n",
    "    u0 = lqr.make_step(x0)\n",
    "    x0 = inverted_pendulum_lin_simulator.make_step(u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "animate_inverted_pendulum_simulation(lqr.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class LQRController:\n",
    "    def __init__(self, lqr: do_mpc.controller.LQR) -> None:\n",
    "        self.lqr = lqr\n",
    "        self.lqr.reset_history()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return lqr.make_step(observation[[1, 3]].reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "max_steps = 500\n",
    "env = create_inverted_pendulum_environment(max_steps=max_steps)\n",
    "controller = LQRController(lqr)\n",
    "results = simulate_environment(env, max_steps=max_steps, controller=controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "media.show_video(results.frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig, ax, graphics = do_mpc.graphics.default_plot(lqr.data, aux_list=[])\n",
    "ax[0].hlines(xss[0], lqr.data._time[0], lqr.data._time[-1], \"r\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Predictive Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Unfortunately, the analytically convenient linear quadratic problem formulations are often not satisfactory. There are two main reasons for this:\n",
    "\n",
    "- The system may be nonlinear, and it may be inappropriate to use for\n",
    "  control purposes. Moreover, some of the control variables may be naturally\n",
    "  discrete, and this is incompatible with the linear system viewpoint.\n",
    "  \n",
    "- There may be control and/or state constraints, which are not handled\n",
    "  adequately through quadratic penalty terms in the cost function. For\n",
    "  example, the motion of a car may be constrained by the presence of\n",
    "  obstacles and hardware limitations.\n",
    "  The solution obtained from a linear quadratic model may not be suitable for such\n",
    "  a problem, because quadratic penalties treat constraints \"softly\"\n",
    "  and may produce trajectories that violate the constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A major difference between MPC and finite-state stochastic control problems\n",
    "that are popular in the RL/artificial intelligence literature is that in MPC\n",
    "the state and control spaces are continuous/infinite, such as for example\n",
    "in self-driving cars, the control of aircraft and drones, or the operation of\n",
    "chemical processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Iterative Linear Quadratic Regulator\n",
    "\n",
    "Iterative Linear Quadratic Regulator (iLQR) is an extension of LQR control to non-linear system with non-linear quadratic costs.\n",
    "\n",
    "The idea is to approximate the cost and dynamics as quadratic and affine, respectively, then exactly solve the resulting LQR problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given a discrete-time non-linear system with state-space representation: \n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t+1} = f(\\mathbf{x}_t, \\mathbf{u}_t)\n",
    "$$\n",
    "\n",
    "we approximate it with a first-order Taylor-series expansion about nominal trajectories\n",
    "$\\mathbf{X} = \\{\\mathbf{x}_0, \\dots, \\mathbf{x}_N\\}, \\mathbf{U} = \\{ \\mathbf{u}_0, \\dots, \\mathbf{u}_N \\}$:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\mathbf{x}_{t+1} + \\delta\\mathbf{x}_{t+1} &= f(\\mathbf{x}_t + \\delta \\mathbf{x}_t, \\mathbf{u}_t + \\delta \\mathbf{u}_t) \\\\ \n",
    "& \\approx f(\\mathbf{x}_t, \\mathbf{u}_t)\n",
    "+ \\frac{\\partial f}{\\partial \\mathbf{x}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{x}_t\n",
    "+ \\frac{\\partial f}{\\partial \\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{u}_t\\\\\n",
    "\\delta\\mathbf{x}_{t+1} &= A_t\\delta\\mathbf{x}_t + B_t\\delta\\mathbf{u}_t\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$\n",
    "A_t = A(\\mathbf{x}_t, \\mathbf{u}_t) = \\frac{\\partial f}{\\partial \\mathbf{x}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\\\\n",
    "B_t = B(\\mathbf{x}_t, \\mathbf{u}_t) = \\frac{\\partial f}{\\partial \\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given a general cost function that is not linear-quadratic, we use a second-order Taylor Series Expansion to linearize the dynamics into a form common for optimal control problems:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "J_N(\\mathbf{x}_0, \\mathbf{U}) &=\n",
    "l_f(\\mathbf{x}_N) + \\sum \\limits_{t=1}^{N-1} l(\\mathbf{x}_t, \\mathbf{u}_t)\\\\\n",
    "&\\approx \\frac{1}{2} \\mathbf{x}^T_N Q \\mathbf{x}_N + q_N^T \\mathbf{x}_N\n",
    "+ \\sum \\limits_{t=1}^{N-1}\n",
    "\\frac{1}{2} \\mathbf{x}^T_t Q_t \\mathbf{x}_t\n",
    "+ \\frac{1}{2} \\mathbf{u}^T_t R_t \\mathbf{u}_t\n",
    "+ \\frac{1}{2} \\mathbf{x}^T_t H_t \\mathbf{u}_t\n",
    "+ \\frac{1}{2} \\mathbf{u}^T_t H_t^T \\mathbf{x}_t\n",
    "+ q_t^T \\mathbf{x}_t +  + r_t^T \\mathbf{u}_t\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We define the following variables for convenience:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "l_x &:= \\frac{\\partial l}{\\partial \\mathbf{x}}|_{\\mathbf{x}_t, \\mathbf{u}_t} = Q_t \\mathbf{x}_t + q_t\n",
    "\\\\\n",
    "l_u &:= \\frac{\\partial l}{\\partial \\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t} = R_t \\mathbf{u}_t + r_t\n",
    "\\\\\n",
    "l_{xx} &:= \\frac{\\partial^2 l}{\\partial \\mathbf{x}^2}|_{\\mathbf{x}_t, \\mathbf{u}_t} = Q_t\n",
    "\\\\\n",
    "l_{uu} &:= \\frac{\\partial^2 l}{\\partial \\mathbf{u}^2}|_{\\mathbf{x}_t, \\mathbf{u}_t} = R_t\n",
    "\\\\\n",
    "l_{xu} &:= \\frac{\\partial^2 l}{\\partial \\mathbf{x}\\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t} = H_t\n",
    "\\\\\n",
    "l_{ux} &:= \\frac{\\partial^2 l}{\\partial \\mathbf{u}\\mathbf{x}}|_{\\mathbf{x}_t, \\mathbf{u}_t} = H_t^T\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can apply Bellman's Principle of Optimality to define the optimal cost-to-go:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "V_N(\\mathbf{x}_N) &= l_f(\\mathbf{x}_N)\\\\\n",
    "V_{t}(\\mathbf{x}_t) &= \\displaystyle \\min_u {l(\\mathbf{x}_{t}, \\mathbf{u}_{t}) + V_{t+1}(f(\\mathbf{x}_{t}, \\mathbf{u}_{N-t}))}\\\\\n",
    "V_{t}(\\mathbf{x}_t) &= \\displaystyle \\min_u Q_{t}(\\mathbf{x}_{t}, \\mathbf{u}_{t})\n",
    "\\end{array}\\\\\n",
    "$$\n",
    "\n",
    "The $Q$-function is the discrete-time analogue of the Hamiltonian, sometimes known as the pseudo-Hamiltonian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We approximate the cost-to-go function as locally quadratic near the nominal trajectory gives us (we drop the time index in some of the equations for the sake of readability):\n",
    "\n",
    "$$\n",
    "\\delta V(\\mathbf{x}) = s^T \\delta\\mathbf{x} + \\frac{1}{2} \\delta\\mathbf{x}^T S \\delta\\mathbf{x}\n",
    "$$\n",
    "\n",
    "with \n",
    "$s = \\frac{\\partial V}{\\partial \\mathbf{x}}|_{\\mathbf{x}},\n",
    "S = \\frac{\\partial^2 V}{\\partial \\mathbf{x}^2}|_{\\mathbf{x}}$\n",
    "\n",
    "Similarily:\n",
    "\n",
    "$$\n",
    "\\delta Q(\\mathbf{x}, \\mathbf{u}) = \n",
    "\\frac{1}{2}\n",
    "\\begin{bmatrix} \\delta\\mathbf{x} \\\\ \\delta\\mathbf{u} \\end{bmatrix}^T\n",
    "\\begin{bmatrix} Q_{xx} & Q_{xu} \\\\ Q_{ux} & Q_{uu} \\end{bmatrix}\n",
    "\\begin{bmatrix} \\delta\\mathbf{x} \\\\ \\delta\\mathbf{u} \\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix} Q_{x} \\\\ Q_{u} \\end{bmatrix}^T\n",
    "\\begin{bmatrix} \\delta\\mathbf{x} \\\\ \\delta\\mathbf{u} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "Q_x &= l_x + s_{t+1} A_t \\\\\n",
    "Q_u &= l_u + s_{t+1} B_t \\\\\n",
    "Q_{xx} &= l_{xx} + A_t^T S_{t+1} A_t \\\\\n",
    "Q_{uu} &= l_{uu} + B_t^T S_{t+1} B_t \\\\\n",
    "Q_{ux} &= l_{ux} + B_t^T S_{t+1} A_t\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The optimal control modification $\\delta\\mathbf{u}^∗$ for some state perturbation $\\delta\\mathbf{x}$, is obtained by minimizing the quadratic model:\n",
    "\n",
    "$$\n",
    "\\delta\\mathbf{u}^∗(\\delta\\mathbf{x}) = \\displaystyle\\arg\\min_{\\delta\\mathbf{u}} Q(\\delta\\mathbf{x}, \\delta\\mathbf{u}) = k + K\\delta\\mathbf{x}\n",
    "$$\n",
    "\n",
    "This is a locally-linear feedback policy with:\n",
    "\n",
    "$$\n",
    "k := -Q_{uu}^{-1}Q_u\\\\\n",
    "K := -Q_{uu}^{-1}Q_{ux}\n",
    "$$\n",
    "\n",
    "Plugging this back into the expansion of $Q$, a quadratic model of $V$ is obtained. After simplification it is:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\Delta V &= \\frac{1}{2} k^T Q_{uu} k + k^T Q_u\\\\\n",
    "s &= Q_x + K^T Q_{uu} k + K^T Q_u + Q_{ux}^T k\\\\\n",
    "S &= Q_{xx} + K^T Q_{uu} K + K^T Q_{ux} + Q_{ux}^T K\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The basic flow of the algorithm is:\n",
    "\n",
    "1. Initialize with initial state $\\mathbf{x}_0$ and initial control sequence $\\mathbf{U} = \\{\\mathbf{u}_{0}, \\mathbf{u}_{1}, \\dots, \\mathbf{u}_{N-1}\\}$.\n",
    "2. Do a forward pass using the non-linear dynamics, i.e. simulate the system using $(\\mathbf{x}_0, \\mathbf{U})$ to get the trajectory through state space, $\\mathbf{X}$, that results from applying the control sequence $\\mathbf{X}$ starting in $\\mathbf{x}_0$.\n",
    "3. Do a backward pass, estimate the value function and dynamics for each $(\\mathbf{x}, \\mathbf{u})$ in the state-space and control signal trajectories.\n",
    "4. Calculate an updated control signal $\\hat{\\mathbf{U}}$ and evaluate cost of trajectory resulting from $(\\mathbf{x}_0, \\hat{\\mathbf{U}})$.\n",
    "   \n",
    "   1. If $|(\\textrm{cost}(x_0, \\hat{\\textbf{U}}) - \\textrm{cost}(x_0, \\textbf{U})| < \\textrm{threshold},$ then we've converged and exit.\n",
    "   2. If $\\textrm{cost}(x_0, \\hat{\\textbf{U}}) < \\textrm{cost}(x_0, \\textbf{U}),$ then set $\\textbf{U} = \\hat{\\textbf{U}},$ and change the update size to be more aggressive. Go back to step 2.\n",
    "   3. If $\\textrm{cost}(x_0, \\hat{\\textbf{U}}) \\geq \\textrm{cost}(x_0, \\textbf{U}),$ change the update size to be more modest. Go back to step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Differential Dynamic Programming\n",
    "\n",
    "Differential Dynamic Programming (DDP) is almost identical to iLQR but unlike the latter, it expands the system's dynamics to the second order i.e. for a given a discrete-time non-linear system with state-space representation: \n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t+1} = f(\\mathbf{x}_t, \\mathbf{u}_t)\n",
    "$$\n",
    "\n",
    "we approximate it with a **second-order** Taylor-series expansion about nominal trajectories\n",
    "$\\mathbf{X} = \\{\\mathbf{x}_0, \\dots, \\mathbf{x}_N\\}, \\mathbf{U} = \\{ \\mathbf{u}_0, \\dots, \\mathbf{u}_N \\}$:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\mathbf{x}_{t+1} + \\delta\\mathbf{x}_{t+1} &= f(\\mathbf{x}_t + \\delta \\mathbf{x}_t, \\mathbf{u}_t + \\delta \\mathbf{u}_t) \\\\ \n",
    "& \\approx f(\\mathbf{x}_t, \\mathbf{u}_t)\n",
    "+ \\frac{\\partial f}{\\partial \\mathbf{x}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{x}_t\n",
    "+ \\frac{\\partial f}{\\partial \\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{u}_t\n",
    "+ \\frac{1}{2} \\left(\n",
    "\\frac{\\partial^2 f}{\\partial \\mathbf{x}^2}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{x}_t^2\n",
    "+ 2 \\frac{\\partial^2 f}{\\partial \\mathbf{x}\\mathbf{u}}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{x}_t\\delta\\mathbf{u}_t\n",
    "+ \\frac{\\partial^2 f}{\\partial \\mathbf{u}^2}|_{\\mathbf{x}_t, \\mathbf{u}_t}\\delta\\mathbf{u}_t^2\n",
    "\\right)\n",
    "\\\\\n",
    "\\delta\\mathbf{x}_{t+1} &= f_x\\delta\\mathbf{x}_t + f_u\\delta\\mathbf{u}_t + \\frac{1}{2} \\left(\n",
    "f_{xx} \\delta\\mathbf{x}_t^2 + 2 f_{xu} \\delta\\mathbf{x}_t \\delta\\mathbf{u}_t + f_{uu} \\delta\\mathbf{u}_t^2\n",
    "\\right)\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which leads to a different expansion of the $Q$-function:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "Q_x &= l_x + f_x^T s_{t+1} \\\\\n",
    "Q_u &= l_u + f_u^T s_{t+1} \\\\\n",
    "Q_{xx} &= l_{xx} + f_x^T S_{t+1} f_x + S_{t+1} \\cdot f_{xx} \\\\\n",
    "Q_{uu} &= l_{uu} + B_t^T S_{t+1} B_t + S_{t+1} \\cdot f_{xu} \\\\\n",
    "Q_{ux} &= l_{ux} + B_t^T S_{t+1} A_t + S_{t+1} \\cdot f_{uu} \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The difference with iLQR is that the last term in the last 3 equations is the product of a vector with a tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The optimal control modification $\\delta\\mathbf{u}^∗$ for some state perturbation $\\delta\\mathbf{x}$, is obtained by minimizing the quadratic model:\n",
    "\n",
    "$$\n",
    "\\delta\\mathbf{u}^∗(\\delta\\mathbf{x}) = \\displaystyle\\arg\\min_{\\delta\\mathbf{u}} Q(\\delta\\mathbf{x}, \\delta\\mathbf{u}) = k + K\\delta\\mathbf{x}\n",
    "$$\n",
    "\n",
    "This is a locally-linear feedback policy with:\n",
    "\n",
    "$$\n",
    "k := -Q_{uu}^{-1}Q_u\\\\\n",
    "K := -Q_{uu}^{-1}Q_{ux}\n",
    "$$\n",
    "\n",
    "Plugging this back into the expansion of $Q$, a quadratic model of $V$ is obtained. After simplification it is:\n",
    "\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "\\Delta V &= -\\frac{1}{2} k^T Q_{uu} k\\\\\n",
    "s &= Q_x - K^T Q_{uu} k\\\\\n",
    "S &= Q_{xx} - K^T Q_{uu} K\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mass-Spring-Damper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpc_params = {\n",
    "    \"n_robust\": 0,\n",
    "    \"n_horizon\": 20,\n",
    "    \"t_step\": env.dt,\n",
    "    \"store_full_solution\": True,\n",
    "}\n",
    "\n",
    "xss = np.array([0.1, 0.0])\n",
    "distance_cost = 100 * casadi.norm_2(mass_spring_damper.x.cat - xss)\n",
    "terminal_cost = distance_cost\n",
    "stage_cost = distance_cost\n",
    "input_penalty = 1e-2\n",
    "\n",
    "mpc = do_mpc.controller.MPC(mass_spring_damper)\n",
    "mpc.set_param(**mpc_params)\n",
    "mpc.set_objective(mterm=terminal_cost, lterm=stage_cost)\n",
    "mpc.set_rterm(force=input_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# lower and upper bounds of the input\n",
    "u_max = 20\n",
    "mpc.bounds[\"lower\", \"_u\", \"force\"] = -u_max\n",
    "mpc.bounds[\"upper\", \"_u\", \"force\"] = u_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpc.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "mpc.reset_history()\n",
    "mass_spring_damper_simulator.reset_history()\n",
    "x0 = np.zeros((2, 1))\n",
    "mass_spring_damper_simulator.x0 = x0\n",
    "mpc.x0 = x0\n",
    "mpc.set_initial_guess()\n",
    "for k in range(100):\n",
    "    u0 = mpc.make_step(x0)\n",
    "    x0 = mass_spring_damper_simulator.make_step(u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "animate_mass_spring_damper_simulation(mpc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class MPCController:\n",
    "    def __init__(self, mpc: do_mpc.controller.MPC) -> None:\n",
    "        self.mpc = mpc\n",
    "        self.mpc.reset_history()\n",
    "        self.mpc.x0 = np.zeros(2)\n",
    "        self.mpc.set_initial_guess()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return mpc.make_step(observation.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "max_steps = 100\n",
    "env = create_mass_spring_damper_environment(max_steps=max_steps)\n",
    "controller = MPCController(mpc)\n",
    "results = simulate_environment(env, max_steps=max_steps, controller=controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "media.show_video(results.frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "animate_mass_spring_damper_simulation(mpc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "- Design an MPC controller for the linearized inverted pendulum.\n",
    "- For each case, try different cost functions:\n",
    "  - $\\sum \\theta^2$\n",
    "  - $\\sum |\\theta|$\n",
    "  - $E_{\\text{kinetic}} - E_{\\text{potential}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Linear Inverted Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "\n",
    "xss = np.array([0.0, 0.0])\n",
    "distance_cost = casadi.sumsqr(inverted_pendulum_lin.x.cat - xss)\n",
    "terminal_cost = distance_cost\n",
    "stage_cost = distance_cost\n",
    "input_penalty = 1e-4\n",
    "\n",
    "mpc_params = {\n",
    "    \"n_robust\": 0,\n",
    "    \"n_horizon\": 50,\n",
    "    \"t_step\": env.dt,\n",
    "    \"store_full_solution\": True,\n",
    "}\n",
    "mpc = do_mpc.controller.MPC(inverted_pendulum_lin)\n",
    "mpc.set_param(**mpc_params)\n",
    "mpc.set_objective(mterm=terminal_cost, lterm=stage_cost)\n",
    "mpc.set_rterm(force=input_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# lower and upper bounds of the input\n",
    "u_max = 3\n",
    "mpc.bounds[\"lower\", \"_u\", \"force\"] = -u_max\n",
    "mpc.bounds[\"upper\", \"_u\", \"force\"] = u_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpc.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "mpc.reset_history()\n",
    "inverted_pendulum_lin_simulator.reset_history()\n",
    "x0 = np.zeros((2, 1))\n",
    "x0[0] = 0.2\n",
    "inverted_pendulum_lin_simulator.x0 = x0\n",
    "mpc.x0 = x0\n",
    "mpc.set_initial_guess()\n",
    "for k in range(100):\n",
    "    u0 = mpc.make_step(x0)\n",
    "    x0 = inverted_pendulum_lin_simulator.make_step(u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "animate_inverted_pendulum_simulation(mpc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class MPCController:\n",
    "    def __init__(self, mpc: do_mpc.controller.MPC) -> None:\n",
    "        self.mpc = mpc\n",
    "        self.mpc.reset_history()\n",
    "        self.mpc.x0 = np.zeros(2)\n",
    "        self.mpc.set_initial_guess()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return mpc.make_step(observation[[1, 3]].reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "max_steps = 500\n",
    "env = create_inverted_pendulum_environment(max_steps=max_steps)\n",
    "controller = MPCController(mpc)\n",
    "results = simulate_environment(env, max_steps=max_steps, controller=controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "media.show_video(results.frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_inverted_pendulum_simulation(mpc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "- Design an MPC Controller for the non-linear inverted pendulum system for two different cases:\n",
    "  1. Cart at origin and upright Pendulm: Set the reference for the cart position to the origin.\n",
    "  2. Pendulum Swing-up: Set the initial angle to to $-\\pi$ i.e. start with the pendulum at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use this to create the environment with initial angle set to -np.pi and cutoff angle to np.inf for second case.\n",
    "env = create_inverted_pendulum_environment(cutoff_angle=np.inf, initial_angle=-np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Cart to Origin and Upright Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "\n",
    "# distance_cost = casadi.bilin(np.diag([0.1, 1000, 0, 0]), inverted_pendulum.x.cat)\n",
    "distance_cost = casadi.norm_2(inverted_pendulum.x[\"theta\"]) + 0.1 * casadi.sumsqr(\n",
    "    inverted_pendulum.x[\"position\"]\n",
    ")\n",
    "terminal_cost = distance_cost\n",
    "stage_cost = distance_cost\n",
    "input_penalty = 0\n",
    "\n",
    "mpc_params = {\n",
    "    \"n_robust\": 0,\n",
    "    \"n_horizon\": 50,\n",
    "    \"t_step\": env.dt,\n",
    "    \"store_full_solution\": True,\n",
    "}\n",
    "mpc = do_mpc.controller.MPC(inverted_pendulum)\n",
    "mpc.set_param(**mpc_params)\n",
    "mpc.set_objective(mterm=terminal_cost, lterm=stage_cost)\n",
    "mpc.set_rterm(force=input_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# lower and upper bounds of the position\n",
    "x_max = 2\n",
    "mpc.bounds[\"lower\", \"_x\", \"position\"] = -x_max\n",
    "mpc.bounds[\"upper\", \"_x\", \"position\"] = x_max\n",
    "# lower and upper bounds of the input\n",
    "u_max = 3\n",
    "mpc.bounds[\"lower\", \"_u\", \"force\"] = -u_max\n",
    "mpc.bounds[\"upper\", \"_u\", \"force\"] = u_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpc.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "mpc.reset_history()\n",
    "inverted_pendulum_simulator.reset_history()\n",
    "x0 = np.zeros((4, 1))\n",
    "x0[1] = 0.2\n",
    "inverted_pendulum_simulator.x0 = x0\n",
    "mpc.x0 = x0\n",
    "mpc.set_initial_guess()\n",
    "for k in range(100):\n",
    "    u0 = mpc.make_step(x0)\n",
    "    x0 = inverted_pendulum_simulator.make_step(u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "animate_mass_spring_damper_simulation(mpc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class MPCController:\n",
    "    def __init__(self, mpc: do_mpc.controller.MPC) -> None:\n",
    "        self.mpc = mpc\n",
    "        self.mpc.reset_history()\n",
    "        self.mpc.x0 = np.zeros(4)\n",
    "        self.mpc.set_initial_guess()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return mpc.make_step(observation.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "max_steps = 500\n",
    "env = create_inverted_pendulum_environment(max_steps=max_steps)\n",
    "controller = MPCController(mpc)\n",
    "results = simulate_environment(env, max_steps=max_steps, controller=controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "media.show_video(results.frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "animate_inverted_pendulum_simulation(mpc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Swing-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "env = create_inverted_pendulum_environment()\n",
    "\n",
    "energy_cost = inverted_pendulum.aux[\"E_kinetic\"] - inverted_pendulum.aux[\"E_potential\"]\n",
    "distance_cost = casadi.bilin(np.diag([1, 1000, 0, 0]), inverted_pendulum.x.cat)\n",
    "terminal_cost = 100 * energy_cost\n",
    "stage_cost = energy_cost\n",
    "input_penalty = 1e-3\n",
    "\n",
    "mpc_params = {\n",
    "    \"n_robust\": 0,\n",
    "    \"n_horizon\": 50,\n",
    "    \"t_step\": env.dt,\n",
    "    \"store_full_solution\": True,\n",
    "}\n",
    "mpc = do_mpc.controller.MPC(inverted_pendulum)\n",
    "mpc.set_param(**mpc_params)\n",
    "mpc.set_objective(mterm=terminal_cost, lterm=stage_cost)\n",
    "mpc.set_rterm(force=input_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# lower and upper bounds of the position\n",
    "x_max = 2\n",
    "mpc.bounds[\"lower\", \"_x\", \"position\"] = -x_max\n",
    "mpc.bounds[\"upper\", \"_x\", \"position\"] = x_max\n",
    "# lower and upper bounds of the input\n",
    "u_max = 3\n",
    "mpc.bounds[\"lower\", \"_u\", \"force\"] = -u_max\n",
    "mpc.bounds[\"upper\", \"_u\", \"force\"] = u_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpc.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "mpc.reset_history()\n",
    "inverted_pendulum_simulator.reset_history()\n",
    "x0 = np.array([0.0, -np.pi, 0.0, 0.0])\n",
    "inverted_pendulum_simulator.x0 = x0\n",
    "mpc.x0 = x0\n",
    "mpc.set_initial_guess()\n",
    "for k in range(100):\n",
    "    u0 = mpc.make_step(x0)\n",
    "    x0 = inverted_pendulum_simulator.make_step(u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "animate_inverted_pendulum_simulation(mpc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class MPCController:\n",
    "    def __init__(self, mpc: do_mpc.controller.MPC) -> None:\n",
    "        self.mpc = mpc\n",
    "        self.mpc.reset_history()\n",
    "        self.mpc.x0 = np.array([0.0, -np.pi, 0.0, 0.0])\n",
    "        self.mpc.set_initial_guess()\n",
    "\n",
    "    def act(self, observation: NDArray) -> NDArray:\n",
    "        return mpc.make_step(observation[[1, 3]].reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "max_steps = 500\n",
    "env = create_inverted_pendulum_environment(\n",
    "    max_steps=max_steps, cutoff_angle=np.inf, initial_angle=-np.pi\n",
    ")\n",
    "controller = MPCController(mpc)\n",
    "results = simulate_environment(env, max_steps=max_steps, controller=controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "media.show_video(results.frames, fps=1 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "animate_inverted_pendulum_simulation(mpc.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPC to AlphaZero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Stochastic Optimal Control\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Markov Decision Process (MDP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Reinforcement Learning\n",
    "\n",
    "Generally, in RL we aim to compute approximately two types of functions, both of which can be computed in principle exactly by Dynamic Programming (DP). These are the optimal value function that provides\n",
    "the optimal cost that can be attained starting from any given initial state, and the optimal policy that provides the optimal decision to apply at any given state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monte Carlo Tree Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "- We learned about Optimal Control and it's connected to Reinforcement Learning.\n",
    "- We learned about LQR, MPC and iLQR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "remove-cell",
     "remove-cell-nbconv"
    ]
   },
   "source": [
    "<img src=\"_static/images/aai-institute-cover.svg\" alt=\"Snow\" style=\"width:100%;\">\n",
    "<div class=\"md-slide title\">Thank you for the attention!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "- [<b id=\"slotine_applied_1991\">[Slotine 1991]</b>](#slotine_applied_1991-back) [Applied nonlinear control.](https://www.academia.edu/download/33582713/Applied_Nonlinear_Control_Slotine.pdf) Slotine, Jean-Jacques E., and Weiping Li. Vol. 199, no. 1. Englewood Cliffs, NJ: Prentice hall. 1991.\n",
    "\n",
    "- [<b id=\"grune_nonlinear_2017\">[Lars Nonlinear 2017]</b>](#grune_nonlinear_2017-back) [Nonlinear model predictive control.](https://link.springer.com/chapter/10.1007/978-3-319-46024-6_3) Grüne, Lars, Jürgen Pannek, Lars Grüne, and Jürgen Pannek. Springer International Publishing, 2017.\n",
    "\n",
    "- [<b id=\"bertsekas_lessons_2022\">[Bertsektas, Dimitri P, 2022]</b>](#bertsekas_lessons_2022-back) [Lessons from AlphaZero for Optimal, Model Predictive, and Adaptive Control](http://web.mit.edu/dimitrib/www/LessonsfromAlphazero.pdf) - Dimitri P. Bertsektas. 2022.\n",
    "- [<b id=\"spencer_optimal_2023\">[Spencer et al. 2023]</b>](#spencer_optimal_2023-back) [AA 203: Optimal and Learning-Based Control.](https://stanfordasl.github.io/aa203/sp2223/) Optimal control solution techniques for systems with known and unknown dynamics. 2023."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "rise": {
   "footer": "<img src='_static/images/aai-logo.png' alt='logo' height='50em'>",
   "header": "<img src='_static/images/transferlab-logo.svg' alt='logo' height='20em' />",
   "theme": "white"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "148px",
    "width": "256px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "563.2px",
    "left": "125px",
    "top": "116.469px",
    "width": "315.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
